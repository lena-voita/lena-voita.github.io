---
layout: lecture
title: Language Modeling
description: Language models (from n-gram to neural) and generation strategies.
---


<div class="sidebar" id="sidebar">
    <div class="sidebar_components">
<a href="javascript:void(0)" id="close_sidebar_btn" onclick="closeNav()"
   style="text-align:center;font-size:30px;padding:0px;">⇤</a>
  <a class="active" href="../nlp_course.html" style="font-weight: bold;">
        <img height="18" class='sidebar_ico' src="../resources/lectures/ico/course_logo.png" style="margin-right: 8px;margin-left: 8px;margin-top: 4px;"/>
        NLP Course <font color="#92bf32" id="for_you_in_sidebar">| For You</font></a>
  <a href="#main_content" style="font-weight: bold;">Language Modeling</a>
    <a href="#intro">What is language modeling?</a>

        <div class="dropdown-scope">
           <a class="dropdown-btn" id="dropdown_general">General Framework
            <i class="fa fa-caret-down"></i>
          </a>
          <div class="dropdown-container">
            <a href="#text_probability"><span style="margin-right:15px;font-size:14px;">&#8226;</span>Text probability</a>
            <a href="#generation"><span style="margin-right:15px;font-size:14px;">&#8226;</span>Generating with LMs</a>
          </div>
        </div>

        <div class="dropdown-scope">
           <a class="dropdown-btn" id="dropdown_ngram">N-gram LMs
            <i class="fa fa-caret-down"></i>
          </a>
          <div class="dropdown-container">
              <a href="#n_gram"><span style="margin-right:15px;font-size:14px;">&#8226;</span>Idea</a>
              <a href="#markov_property"><span style="margin-right:15px;font-size:14px;">&#8226;</span>Markov property</a>
              <a href="#n_gram_smoothing"><span style="margin-right:15px;font-size:14px;">&#8226;</span>Smoothing</a>
              <a href="#n_gram_generation"><span style="margin-right:15px;font-size:14px;">&#8226;</span>Generation and Examples</a>
          </div>
        </div>

         <div class="dropdown-scope">
           <a class="dropdown-btn" id="dropdown_neural">Neural LMs
            <i class="fa fa-caret-down"></i>
          </a>
          <div class="dropdown-container">
              <a href="#neural_lms"> <span style="margin-right:15px;font-size:14px;">&#8226;</span> Idea</a>
              <a href="#neural_high_level_pipeline"><span style="margin-right:15px;font-size:14px;">&#8226;</span>High-Level Pipeline</a>
              <a href="#neural_lms_training"><span style="margin-right:15px;font-size:14px;">&#8226;</span>Training</a>
              <a href="#neural_lms_models_rnn"><span style="margin-right:15px;font-size:14px;">&#8226;</span>Models: Recurrent</a>
              <a href="#neural_lms_models_cnn"><span style="margin-right:15px;font-size:14px;">&#8226;</span>Models: Convolutional</a>
          </div>
        </div>


          <div class="dropdown-scope">
           <a class="dropdown-btn" id="dropdown_neural">Generation strategies
            <i class="fa fa-caret-down"></i>
          </a>
          <div class="dropdown-container">
              <a href="#generation_strategies"> <span style="margin-right:15px;font-size:14px;">&#8226;</span>Goal: Coherence and Diversity</a>
              <a href="#generation_strategies_sampling"> <span style="margin-right:15px;font-size:14px;">&#8226;</span>Sampling</a>
              <a href="#generation_strategies_temperature"><span style="margin-right:15px;font-size:14px;">&#8226;</span>Sampling with Temperature</a>
              <a href="#generation_strategies_top_k"><span style="margin-right:15px;font-size:14px;">&#8226;</span>Top-K Sampling</a>
              <a href="#generation_strategies_top_p"><span style="margin-right:15px;font-size:14px;">&#8226;</span>Top-p (Nucleus) Sampling</a>
          </div>
        </div>


        <a href="#evaluation">Evaluation</a>

         <div class="dropdown-scope">
           <a class="dropdown-btn">Practical Tips
            <i class="fa fa-caret-down"></i>
          </a>
          <div class="dropdown-container">
              <a href="#weight_tying_trick"> <span style="margin-right:15px;font-size:14px;">&#8226;</span>Weight Tying</a>
              <!--<a href="#label_smoothing"> <span style="margin-right:15px;font-size:14px;">&#8226;</span>Label Smoothing</a>-->
          </div>
        </div>

<a href="#analysis_interpretability" id="sidebar_analysis">Analysis and Interpretability
    <img height="25" src="../resources/lectures/ico/analysis_empty.png" class="sidebar_ico"/></a>
<div class="extra_components">
    <a href="#research_thinking" id="sidebar_research_thinking">Research Thinking
        <img height="30" src="../resources/lectures/ico/bulb_empty.png" class="sidebar_ico"/></a>
    <!--<hr color="#b7db67">-->

    <a href="#related_papers" id="sidebar_related_papers">Related Papers
        <img height="22" src="../resources/lectures/ico/book_empty.png" class="sidebar_ico"/></a>
    <!--<hr color="#b7db67">-->

  <a href="#have_fun" id="sidebar_fun">Have Fun! <img height="30" src="../resources/lectures/ico/fun_empty.png" class="sidebar_ico"/></a>
</div>
</div>
    </div>



<div class="sidebar" id="sidebar_small">

  <a class="active" onclick="openNav()" style="text-align:center;">☰</a>
    <a class="active" href="../nlp_course.html" style="font-weight: bold;">
        <img height="20" src="../resources/lectures/ico/course_logo.png" style="margin-right: 8px;margin-left: 8px;"/></a>
    <a href="#main_page_content" style="text-align:center; font-size:20px;color:#7ca81e"> <i class="fa fa-home"></i></a>

<a href="#analysis_interpretability" id="sidebar_analysis"> <img height="25" src="../resources/lectures/ico/analysis_empty.png"/></a>
<div class="extra_components">
    <a href="#research_thinking" id="sidebar_research_thinking"><img height="30" src="../resources/lectures/ico/bulb_empty.png"/></a>
    <!--<hr color="#b7db67">-->

    <a href="#related_papers" id="sidebar_related_papers"><img height="22" src="../resources/lectures/ico/book_empty.png"/></a>
    <!--<hr color="#b7db67">-->

  <a href="#have_fun" id="sidebar_fun"><img height="30" src="../resources/lectures/ico/fun_empty.png" /></a>
</div>
</div>


<script>
function openNav() {
  document.getElementById("sidebar").style.display = "block";
  document.getElementById("sidebar_small").style.display = "none";
  document.getElementById("close_sidebar_btn").style.display = "block";
}

function closeNav() {
  document.getElementById("sidebar").style.display = "none";
  document.getElementById("sidebar_small").style.display = "block";
  document.getElementById("close_sidebar_btn").style.display = "none";
}

</script>


<script>
function onResize() {
  if (window.innerWidth >= 800) {
     document.getElementById("sidebar").style.display = "block";
     document.getElementById("sidebar_small").style.display = "none";
     document.getElementById("close_sidebar_btn").style.display = "none";
  }
  else {
     document.getElementById("sidebar").style.display = "none";
    document.getElementById("sidebar_small").style.display = "block";

  }
}
window.onresize = onResize;
onResize();
</script>

<script>
/* Loop through all dropdown buttons to toggle between hiding and showing its dropdown content - This allows the user to have multiple dropdowns without any conflict */
var dropdown = document.getElementsByClassName("dropdown-btn");
var i;

for (i = 0; i < dropdown.length; i++) {
  dropdown[i].addEventListener("click", function(event) {
  this.classList.toggle("active_caret");
  var dropdownButton = event.target || event.srcElement;
  while(dropdownButton.className != "dropdown-scope")
     dropdownButton = dropdownButton.parentElement;
  var dropdownContent = dropdownButton.getElementsByClassName("dropdown-container")[0];

  if (dropdownContent.style.display === "block") {
  dropdownContent.style.display = "none";
  } else {
  dropdownContent.style.display = "block";
  }
  });
}
</script>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.1.0/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-vis@1.0.2/dist/tfjs-vis.umd.min.js"></script>
<script src="https://d3js.org/d3.v3.min.js" charset="utf-8"></script>

<style>
        :root{}
        .lm_window {
            width: 100%;
            border: 1px solid #ccc;
            border-radius: 1px;
            margin: 10px 5px;
            padding: 3px;
            background-color: white;
            text-align: center;
        }
        #lm_window {
            box-shadow: 0 2px 4px #377b94, 0 1px 1px ;
          }
        #lm_window:hover {
            box-shadow: 0 6px 12px #377b94, 0 4px 4px #377b94;
          }
        .prompt_text {
            font-size: 24px;
            font-family: "Comic Neue", "Arial";
            margin-top: 10px;
            margin-bottom: 10px;
            font-weight: bold;
            text-align: center;
            background-color: #ebf6fa;
        }
        .comment_text {
            font-size: 16px;
            font-family: "Gill Sans", sans-serif;
            font-style: italic;
            text-align: center;
        }
        .rect_button {
          width: 25%;
          background-color: #fafafa;
          font-size: 20px;
          font-family: "Comic Neue", "Arial";
          font-weight: bold;
          color: black;
          margin-right: 20px;
          margin-left: 20px;
          margin-top: 10px;
          margin-bottom: 10px;
          border: 0px solid black;
          border-radius: 12px;
          padding: 20px;
          padding-top: 0px;
          padding-bottom: 0px;
          text-decoration: none;
          display: inline-block;
          text-align: center;
          box-shadow: 0px 2px 3px #377b94, 0 1px 1px #377b94;
        }
        .rect_button:hover {
            box-shadow: 0 3px 6px #377b94, 0 2px 2px #377b94;
        }
        .button_text {
            margin-top: 3px;
            margin-bottom: 3px;
        }
        .prompt_and_button {
            display: grid;
            grid-template-columns: auto 30px;
        }
        .next_button {
            width: 0;
            height: 0;
            border-top: 30px solid transparent;
            border-left: 45px solid #1b6f8c;
            border-bottom: 30px solid transparent;
        }
        .next_text {
            color: #1b6f8c;
            font-style: italic;
            font-weight: 600;
            font-family: "Comic Neue", "Arial";
            margin: 0 auto;
        }
        .axis path, .axis line {
            fill: none;
            stroke: black;
            shape-rendering: crispEdges;  /* Round any decimal pixels so it'll render nicely */
        }
    </style>


<div class="wrapper" id="main_page_content">
    <div class="header"><h1>Language Modeling</h1></div>

<div class="main_content" id="main_content">




<div id="intro">

    <h2>What does it mean to "model something"?</h2>
    <p>Imagine that we have, for example, a model of a physical world.
       What do you expect it to be able to do? Well, if it is a good model,
          it probably can predict what happens next given some description of
        "context", i.e., the current state of things.
        Something of the following kind:</p>

        <p class="data_text" style="margin-left:30px;">We have a tower of that many toy cubes
        of that size made from this material.
        We push the bottom cube from this point in that direction
            with this force. What will happen?</p>

    <p>A good model would simulate the behavior of the real world: it would "understand"
        which events are in better agreement with the world, i.e., which of them are
        <font face="arial">more likely</font>.</p>

    <h2>What about language?</h2>

    <p>For language, the intuition is exactly the same! What is different, is the notion of an
    <font face="arial">event</font>.
    In language, an <font face="arial">event</font> is a linguistic unit (text, sentence, token, symbol),
        and a goal of a language model is to estimate the probabilities of these events.</p>

    <div class="green_left_thought" style="font-size:18px;">
        <p class="data_text">Language Models (LMs) estimate the probability of
            different linguistic units: symbols, tokens, token sequences.</p>
    </div>


    <p>But how can this be useful?</p>

     <div class="carousel" data-flickity='{ "imagesLoaded": true, "percentPosition": true, "wrapAround": true }'
     style="width:50%; margin-bottom:30px; margin-left:10px; float:right;">
              <div class="carousel-cell" style="width:100%"><center>
                    <img width=70% src="../resources/lectures/lang_models/examples/suggest-min.png"/></center>
              </div>
              <div class="carousel-cell" style="width:100%"><center>
                    <img width=70% src="../resources/lectures/lang_models/examples/autocompletion-min.png"/></center>
              </div>
              <div class="carousel-cell" style="width:100%"><center>
                    <img width=70% src="../resources/lectures/lang_models/examples/misspell_mt-min.png"/></center>
              </div>
              <div class="carousel-cell" style="width:100%"><center>
                    <img width=70% src="../resources/lectures/lang_models/examples/misspell-min.png"/></center>
              </div>
      </div>
<h2>We deal with LMs every day!</h2>

    <p>We see language models in action every day - look at some examples. Usually models
    in large commercial services
    are a bit more complicated than the ones we will discuss today, but the idea is the same:
    if we can estimate probabilities of words/sentences/etc, we can use them in
    various, sometimes even unexpected, ways.</p>


    <h2>What is easy for humans, can be very hard for machines</h2>

        <center>
        <img src="../resources/lectures/lang_models/examples/morphosyntax-min.png"
             style="max-width:80%; margin-bottom:15px;"/>
            <div style="font-size:14px; margin-left: 30px; margin-right: 30px;" class="data_text">
                <font color="#888">
                <u>Lena</u>: The <span  style="font-weight:bold;">morphosyntax</span> example is from
                    the slides by Alex Lascarides and Sharon Goldwater,<br>
                    Foundations of Natural Language Processing course at the University of Edinburgh.</font>
            </div>
        </center>
<br>

    <p>We, humans, already have some feeling of "probability" when it comes to natural language.
    For example, when we talk, usually we understand each other quite well
    (at least, what's being said). We disambiguate between different options which sound similar
    without even realizing it!</p>


    <p>But how a machine is supposed to understand this?
        A machine needs a language model, which estimates the probabilities of sentences.
        If a language model is good, it will assign a larger probability to a correct option.
    </p>

</div>




<div id="general">
    <h1>General Framework</h1>

    <h2 id="text_probability">Text Probability</h2>
    <p>Our goal is to estimate probabilities of text fragments; for simplicity, let's
        assume we deal with sentences. We want
        these probabilities to reflect knowledge of a language. Specifically, we want
        sentences that are "more likely" to appear in a language to have a larger probability
        according to our language model.
    </p>

    <h3><u>How likely is a sentence to appear in a language?</u></h3>
    <center>
        <img src="../resources/lectures/lang_models/general/probability_simple_vs_sentence-min.png"
             style="max-width:100%; margin-bottom:10px;"/>
    </center>

    <!--<img src="../resources/lectures/lang_models/general/balls-min.png"
         style="float:right; margin-left: 25px; max-width:20%"/>-->

    <p> <!--How can we estimate the probability of a sentence?-->
        Let's check if simple probability theory can help.
        Imagine we have a basket with balls of different colors. The probability to
        pick a ball of a certain color (let's say green) from this basket
        is the frequency with which green balls occur in the basket.
    </p>

    <!--<img src="../resources/lectures/lang_models/general/frequency_language-min.png"
         style="float:right; margin-left: 25px; max-width:35%"/>-->

    <p>What if we do the same for sentences?
        Since we can not possibly have a text corpus that contains all sentences in a natural language,
        a lot of sentences will not occur in the corpus.
        While among these sentences some are clearly more likely than the others,
        all of them will receive zero probability, i.e., will look equally bad for the model.
        This means, the method is not good and we have to do something more clever.
    </p>

    <h3><u>Sentence Probability: Decompose Into Smaller Parts</u></h3>

    <p>We can not reliably estimate sentence probabilities if we treat them as atomic units.
        Instead, let's decompose the probability of a sentence into probabilities of smaller parts.</p>

    <p>For example, let's take the sentence
        <span class="data_text"><strong>I saw a cat on a mat</strong></span>
    and imagine that we read it word by word.
        At each step,  we estimate the probability of
        all seen so far tokens. We don't want any computations not to be in vain (no way!), so we
        won't throw away previous probability once a new word appears: we
        will update it to account for a new word. Look at the illustration.
    </p>

    <center>
        <img src="../resources/lectures/lang_models/general/icons8-kitty-100.png"
             style="height:40px;float:right;margin-top:30px;"/>
        <img src="../resources/lectures/lang_models/general/i_saw_a_cat_prob.gif"
             style="max-width:80%; margin-bottom:10px;"/>
    </center>


    <p>Formally, let \(y_1, y_2, \dots, y_n\) be tokens in a sentence, and
        \(P(y_1, y_2, \dots, y_n)\) the
    probability to see all these tokens (in this order). Using
        the product rule of probability (aka the chain rule), we get
    \[P(y_1, y_2, \dots, y_n)=P(y_1)\cdot P(y_2|y_1)\cdot P(y_3|y_1, y_2)\cdot\dots\cdot P(y_n|y_1, \dots, y_{n-1})=
        \prod \limits_{t=1}^n P(y_t|y_{\mbox{<}t}).\]
    We decomposed the probability of a text into conditional probabilities of each token given the previous context.
    </p>


    <h3><u>We got: Left-to-Right Language Models</u></h3>
    <img src="../resources/lectures/lang_models/general/need_to_define-min.png"
         style="float:right; margin-left: 25px; max-width:45%"/>
    <p>What we got is the standard left-to-right language modeling framework. This framework
        is quite general: N-gram and neural language models differ only in a way they compute the
        conditional probabilities \(P(y_t|y_1, \dots, y_{t-1})\).
    </p>

    <p class="data_text"><font color="#888">
        <u>Lena</u>: Later in the course we will see other language models: for example, Masked Language Models or
        models that decompose the joint probability differently (e.g., arbitrary order of tokens and not fixed as
        the left-to-right order).</font></p>

    <p>We will come to specifics of N-gram and neural models a bit later. Now,
        we discuss <!--two more things which apply to both of them: how to <font face="arial">evaluate</font>
        a language model and--> how to generate a text using a language model.
    </p>


    <br>

    <h2 id="generation">Generate a Text Using a Language Model</h2>

    <p>Once we have a language model, we can use it to generate text. We do it one token at a time:
        predict the probability distribution of the next token given previous context, and sample from this
        distribution.
    </p>

    <!--<img height="20" src="../resources/lectures/ico/paw_empty.png" style="float:left; margin-top:-10px;"/>
    <div class="box_green_left">
        <div class="text_box_green" style="margin-bottom:15px;">
            <p class="data_text">
                <u>How to:</u> Look at the illustration of the generation process.</p>
        </div>-->
        <video width="70%" height="auto" loop autoplay muted style="margin-left: 20px;">
          <source src="../resources/lectures/lang_models/general/generation_example.mp4" type="video/mp4">
        </video>
    <!--</div>
    <img height="20" src="../resources/lectures/ico/paw_empty.png" style="float:left; margin-top:-10px;"/>-->



    <p>Alternatively, you can apply  <font face="arial">greedy decoding</font>:
        at each step, pick the token with the highest probability. However, this
        usually does not work well: a bit later I will show you examples from real models.</p>

    <p>Despite its simplicity, such sampling is quite common in generation. In section
    <a href="#generation_strategies">Generation Strategies</a>
        we will look at different modifications of this
        approach to get samples with certain qualities; e.g., more or less "surprising".
    </p>



</div>




<br>

<div id="n_gram">
    <h1>N-gram Language Models</h1>

    <p>Let us recall that <a href="#general">the general left-to-right language modeling framework</a>
    decomposes probability  of a token sequence,
     <!--\(P(x_1, x_2, \dots, x_n)\),-->
    into conditional probabilities of each token given previous context:
    \[P(y_1, y_2, \dots, y_n)=P(y_1)\cdot P(y_2|y_1)\cdot P(y_3|y_1, y_2)\cdot\dots\cdot P(y_n|y_1, \dots, y_{n-1})=
        \prod \limits_{t=1}^n P(y_t|y_{\mbox{<}t}).\]
    The only thing which is not clear so far is how to compute these probabilities.
    </p>

    <div class="green_left_thought">
                <p class="data_text" style="font-size:18px;"><u>We need to</u>:
                    define how to compute the
        conditional probabilities \(P(y_t|y_1, \dots, y_{t-1})\).</p>
        </div>

    <p>Similar to count-based methods we saw earlier in the
        <a href="./word_embeddings.html" target="_blank">Word Embeddings</a> lecture,
        n-gram language models also <font face="arial">count</font> global statistics from a text corpus.</p>

    <div class="green_left_thought">
    <p class="data_text" style="font-size:18px;"><u>How</u>:
                    estimate based on global statistics from a text corpora, i.e., <strong>count</strong>.</p></div>

    <p>That is, the way n-gram LMs estimate probabilities \(P(y_t|y_{\mbox{<}t}) = P(y_t|y_1, \dots, y_{t-1})\)
        is <font face="arial">almost</font> the same as the way we earlier <!--<a href="#text_probability">earlier</a>-->
        estimated the
        probability to pick a green ball from a basket.
        This innocent <font face="arial">"almost"</font>
        contains the key components of n-gram LMs:
        <font face="arial">Markov property</font> and <font face="arial">smoothings</font>.
    </p>

    <div id="markov_property">
        <h2>Markov Property (Independence Assumption)</h2>

        <p>The straightforward way to compute \(P(y_t|y_1, \dots, y_{t-1})\) is
        \[P(y_t|y_1, \dots, y_{t-1}) = \frac{N(y_1, \dots, y_{t-1}, y_t)}{N(y_1, \dots, y_{t-1})},\]
            where \(N(y_1, \dots, y_k)\) is the number of times a sequence of tokens
            \((y_1, \dots, y_k)\) occur in the text.</p>

        <p>For the same reasons we discussed before, this won't work well: many of the fragments \((y_1, \dots, y_{t})\)
            do not occur in a corpus and, therefore, will zero out the probability of the sentence.
            To overcome this problem,
            we make an independence assumption (assume that the Markov property holds):
        </p>
        <div class="green_left_thought">
        <p class="data_text" style="font-size:18px;">
            The probability of a word only depends on a <strong>fixed</strong>
            number of previous words.
        </p></div>
        Formally, n-gram models assume that
        \[P(y_t|y_1, \dots, y_{t-1}) = P(y_t|y_{t-n+1}, \dots, y_{t-1}).\]
        For example,
        <ul>
            <li>n=3 (trigram model): \(P(y_t|y_1, \dots, y_{t-1}) = P(y_t|y_{t-2}, y_{t-1})\),</li>
            <li>n=2 (bigram model): \(P(y_t|y_1, \dots, y_{t-1}) = P(y_t|y_{t-1})\),</li>
            <li>n=1 (unigram model): \(P(y_t|y_1, \dots, y_{t-1}) = P(y_t)\).</li>
        </ul>

        <p>Look how the standard decomposition changes for n-gram models.</p>

        <img width="80%" src="../resources/lectures/lang_models/ngram/example_cut_3gram-min.png"/>

    </div>

    <br>


    <div id="n_gram_smoothing">
        <h2>Smoothing: Redistribute Probability Mass</h2>

        <p>Let's imagine we deal with a 4-gram language model and consider the following example:

        </p>
        <center>
        <img width="70%" src="../resources/lectures/lang_models/ngram/prob_cat_on_a_mat-min.png"
        style="margin-bottom: 15px;"/>
        </center>

        <p>What if either denominator or numerator is zero? Both these cases are not really good for the model.
        To avoid these problems (and some other),
            it is common to use <font face="arial">smoothings</font>. Smoothings redistribute
            probability mass: they "steal" some mass from seen events and give to the unseen ones.
        </p>

        <p class="data_text"><font color="#888"><u>Lena</u>: at this point, usually I'm
            tempted to imagine
        a brave Robin Hood, stealing from the rich and giving to the poor -
            just like  smoothings do with the probability mass.
            Unfortunately, I have to stop myself, because, let's be honest,
            smoothings are not so clever - it would
        be offensive to Robin. </font></p>



        <h3><u>Avoid zeros in the denominator</u></h3>
        <img width="45%" src="../resources/lectures/lang_models/ngram/denominator_zero-min.png"
         style="float:right; margin-left:30px;"/>

        <p>If the phrase <span class="data_text"><strong>cat on a</strong></span> never appeared in our
            corpus, we will not be able to compute the probability. Therefore, we need a
            "plan B" in case this happens.
        </p>
        <br>

        <div id="smoothing_stupid_backoff" style="margin-left:40px;">
            <img width="35%" src="../resources/lectures/lang_models/ngram/backoff-min.png"
             style="float:right; margin-left:30px;"/>
            <h4><u>Backoff (aka Stupid Backoff)</u></h4>
            <p>
                One of the solutions is to use less context for context we don't know much about.
                This is called <font face="arial">backoff:</font>
                <ul>
                <li>if you can, use trigram;</li>
                <li>if not, use bigram;</li>
                <li>if even bigram does not help, use unigram.</li>
                </ul>
            This is rather stupid (hence the title), but works fairly well.
            </p>
        </div>
        <br>

        <div id="smoothing_interpolation" style="margin-left:40px;">
            <h4><u>More clever: Linear interpolation</u></h4>
            <p>
                A more clever solution is to mix all probabilities: unigram, bigram, trigram, etc.
                For this, we need scalar positive weights \(\lambda_0, \lambda_1, \dots, \lambda_{n-1}\)
                such that \(\sum\limits_{i}\lambda_i=1\). Then the updated probability is:
                <center>
                <img width="45%" src="../resources/lectures/lang_models/ngram/interpolation-min.png"
             style="margin-bottom:15px;"/>
                </center>
            The coefficients \(\lambda_i\) can be picked by cross-validation on the development set.
            You will be able to do this once you know how to evaluate language models: see the
            <a href="#evaluation">Evaluation</a> section.
            </p>
        </div>


        <h3><u>Avoid zeros in the numerator</u></h3>
        <img width="50%" src="../resources/lectures/lang_models/ngram/numerator_zero-min.png"
         style="float:right; margin-left:30px;"/>

        <p>If the phrase <span class="data_text"><strong>cat on a mat</strong></span> never appeared in our
            corpus, the probability of the whole sentence will be zero - but this does not mean
            that the sentence is impossible! To avoid this, we also need a
            "plan B".
        </p>
        <br>

        <div id="smoothing_laplace" style="margin-left:40px;">
            <h4><u>Laplace smoothing (aka add-one smoothing)</u></h4>
            <p>
                The simplest way to avoid this is just to
                <font face="arial">pretend</font> we saw all n-grams <font face="arial">at least one time:</font>
                just add 1 to all counts! Alternatively, instead of 1, you can add a small \(\delta\):
            </p>
                <center>
                <img width="45%" src="../resources/lectures/lang_models/ngram/laplace-min.png"/>
                </center>
        </div>


        <br>

     <h3><u>More Clever Smoothings</u></h3>

    <!--<div class="card_with_ico">
        <img class="ico" width="40" src="../resources/lectures/ico/book_empty.png"/>
        <div class="text_box_pink">
            <p class="data_text">

                <strong>Good-Turing Smoothing.</strong><br>
                    <a href="papers_smoothings">More details are here.</a>
            <font color="red">link to Kneser-Ney and Good Turing</font>
            </p>
        </div>
    </div>
-->
    <div class="card_with_ico">
        <img class="ico" width="40" src="../resources/lectures/ico/book_empty.png"/>
        <div class="text_box_pink">
            <p class="data_text">

                <strong>Kneser-Ney Smoothing.</strong><br>
                The most popular smoothing for n-gram LMs is Kneser-Ney smoothing:
                 it is a more clever variant of the back-off.
                    <a href="#papers_smoothings">More details are here.</a>
            </p>
        </div>
    </div>


    </div>



    <div id="n_gram_generation">
        <h2>Generation (and Examples)</h2>

        <p>The generation procedure for a n-gram language model is
            the same as the general one: given current context (history), generate a probability distribution
            for the next token (over all tokens in the vocabulary), sample a token, add this token to
            the sequence, and repeat all steps again.
            The only part which is specific to n-gram models is the way we compute the probabilities.
            Look at the illustration.
        </p>

            <video width="70%" height="auto" loop autoplay muted style="margin-left: 20px;">
              <source src="../resources/lectures/lang_models/general/generation_ngram.mp4" type="video/mp4">
            </video>

<h3 id="ngram_sample_examples"><u>Examples of generated text</u></h3>

        <p>To show you some examples, we trained a 3-gram model on 2.5 million English sentences.</p>

            <p class="data_text" style="font-size:14px"><font color="#888"><u>Dataset details.</u>
                The data is the English
                side of WMT English-Russian translation data. It consists of 2.5 million sentence pairs
                (a pair of sentences in English and Russian which are supposed to be translations of each other).
                The dataset
                contains news data, Wikipedia titles and 1 million crawled sentences released by Yandex.
                This data is one of the standard datasets for machine translation; for language modeling,
                we used only the English side.
            <br><br>
                Note that everything you will see below is generated by a model and presented
                without changes or filtering. Any content you might not like
                appeared as a result of training data. The best we can do is to use the standard datasets, and we did.
            </font></p><br>



        <img height="20" src="../resources/lectures/ico/paw_empty.png" style="float:left; margin-top:-10px;"/>
        <div class="box_green_left">

            <div class="text_box_green">

                <p class="data_text">
                    <u>How to:</u> Look at the samples from a n-gram LM. What is clearly wrong
                with these samples? What in the design of n-gram models leads to this problem?
                </p>
            </div>



             <div class="carousel" data-flickity='{ "imagesLoaded": true, "percentPosition": true, "wrapAround": true}'
     style="width:100%; margin-top:10px; margin-bottom:30px; margin-left:10px;">

                  <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            so even when i talk a bit short , there was no easy thing to do different buffer
                             flushing strategies in the future , due to huge list of number - one just has started
                             production of frits in the process and has free wi - fi ” operation .... _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             he can perform the dual monarchy arrived in moscow lying at two workshops one in all
                             schools of political science ..." and then you can also benefit from your service . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             alas , still in the lower left corner will not start in 1989 . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             john holmes is a crystal - clear spring of 2001 . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             it simply yields a much later , there were present , ferrocenecontaining compounds
                             for clinical trials in connection with this chapter you ' re looking for ways of payment
                             and insert preferred record into catalogue of negative influences - military . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             impotence in the way gazprom and its environment . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             according to the address and tin box , luggage storage , gay friendly , all of europe to code - transitions . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             26 . 01 page 2 introduction the challenge for the horizontal scroll bar in sweden , austria _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             the rza lyrics are brought to you , there are a few . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             golden sands , once again the only non - governmental organizations recognized by the objector . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             hahn , director of the christian " love and compassion " was designed as a result of any form ,
                             in the transaction is active in the stuva grill . _eos_ </p>
                     </div>
                 </center>
                 </div>


                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             there is a master ’ s a major bus routes in and the us became israel were rewarded with
                             an electric air conditioning television satellite television . _eos_ </p>
                     </div>
                 </center>
                 </div>


                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            , we have had , 1990 in aksaray – turkey has provided application is built on low - power plants . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             when this option may be the worst day of amnesty international delegations visited israel ,
                             and felt that his sisters , that they are reserved for zyryanovsk concentrating factory
                             there is a member of the shire ," given as to damage the expansion of a meeting over a
                             large health maintenance organization , smoking , airconditioning , designated smoking area . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             4 . 0 beta has been received the following initiatives in order to meet again in 1989 ,
                             and in the face of director of branch offices in odessa on time , the church of norway is
                             an advertisement for the protection the d - 54673 , limousine , employee badges , etc )
                             downloading this icecat data - do can talk about israel as well as standard therapy of
                             czech republic estonia greece france ireland israel italy jamaica japan jordan kazakhstan
                             kenya kiribati kuwait kyrgyzstan lao people ' s closing of the task of mill -
                             a fire that _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             one lesson the teacher ! _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             pupils from eastern europe , africa , saudi arabia ’ s church , yearn for such an
                             open structure of tables several times on monday 14 september 2003 , his flesh when
                             i was curious to know and also to find what they are constructed with a
                             speeding arrow . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             blackjack : six steps to resolve complex social adaptation of the room ' s polyclinics and to english . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            this is the right nanny jobs easier for people to take part in the history of england
                             has a large number of regional and city administration . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            melody for the acquisition , provision or condition . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            they have a proper map that force distant astronomical objects have been soaring among ukrainians - warriors ". _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            also now recognizing how interdependent they are successful in emulating poland ’ s satisfaction . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            we tried to make lyrics as correct as possible , however if you have any corrections for
                             abecedário da xuxa lyrics are brought to you by lyrics - keeper . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            49 . 99 webmoney rub , 893 . 6 million euros . _eos_ </p>
                     </div>
                 </center>
                 </div>


            </div>

        </div>
        <img height="20" src="../resources/lectures/ico/paw_empty.png" style="float:left; margin-top:-10px;"/>

        <br><br>

        <p>You probably noticed that these samples are not fluent: it can be clearly seen
        that the model does not use long context, and relies only on a couple of tokens.
            <font face="arial">The inability to use
                long contexts</font> is
        the main shortcoming of n-gram models.</p>

        <p>Now, we take the same model, but perform greedy decoding:
                    at each step,
                    we pick the token with the highest probability. We used 2-token prefixes
                    from the examples of samples above (for each example,
                    the prefix fed to the model is underlined).
        </p><br>

        <img height="20" src="../resources/lectures/ico/paw_empty.png" style="float:left; margin-top:-10px;"/>
        <div class="box_green_left" id="ngram_samples_examples">

            <div class="text_box_green">

                <p class="data_text">
                    <u>How to:</u> Look at the examples generated by the same model using greedy decoding.

                    Do you like these texts? How would you describe them?
                </p>
            </div>



             <div class="carousel" data-flickity='{ "imagesLoaded": true, "percentPosition": true, "wrapAround": true}'
     style="width:100%; margin-top:10px; margin-bottom:30px; margin-left:10px;">

                  <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>so even</u> if the us , and the united states , the hotel is located in the list of
                             songs , you can add them in our collection by this form . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>he can</u> be used to be a good idea to the keyword / phrase business intelligence
                             development studio . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>alas ,</u> the hotel is located in the list of songs , you can add them in our collection by this form . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>john holmes</u> _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>it simply</u> , the hotel is located in the list of songs , you can
                             add them in our collection by this form . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>impotence in</u> the list of songs , you can add them in our collection by this form . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>according to</u> the keyword / phrase business intelligence development studio . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>26 .</u> _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>the rza</u> ( bobby digital ) is a very good .  _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>golden sands</u> resort .  _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>hahn ,</u> of the world . _eos_ </p>
                     </div>
                 </center>
                 </div>


                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>there is</u> a very good . _eos_ </p>
                     </div>
                 </center>
                 </div>


                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>, we</u> a good idea to the keyword / phrase business intelligence development studio . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>when this</u> option is to be a good idea to the keyword / phrase business intelligence development studio . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>4 .</u> 5 % of the world . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>one lesson</u> from the city of the world . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>pupils from</u> the city of the world . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>blackjack :</u> six - party talks . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>this is</u> the most important thing is that the us , and the united states ,
                             the hotel is located in the list of songs , you can add them in our collection by this form . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>melody for</u> two years , the hotel is located in the list of songs , you can add them in our collection by this form . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>they have</u> been a member of the world . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>also now</u> possible to use the " find in page " function below . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>we tried</u> to make lyrics as correct as possible , however if you have any
                             corrections for the first time in the list of songs , you can add them in our
                             collection by this form . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             <u>49 .</u> _eos_ </p>
                     </div>
                 </center>
                 </div>


            </div>

        </div>
        <img height="20" src="../resources/lectures/ico/paw_empty.png" style="float:left; margin-top:-10px;"/>

<br><br>

        <p>We see that greedy texts are:</p>
        <ul>
            <li>shorter - the <font face="courier">_eos_</font> token has high probability;</li>
            <li>very similar - many texts end up generating the same phrase.</li>
        </ul>

        <p>To overcome the main flaw of n-gram LMs, fixed context size, we will now come to neural models.
            As we will see later, when longer contexts are used, greedy decoding is not so awful.</p>

    </div>


</div>


<br><br>

<div id="neural_lms">
    <h1>Neural Language Models</h1>

    <p>In <a href="#general">our general left-to-right language modeling framework</a>,
    the probability  of a token sequence
     is:
    \[P(y_1, y_2, \dots, y_n)=P(y_1)\cdot P(y_2|y_1)\cdot P(y_3|y_1, y_2)\cdot\dots\cdot P(y_n|y_1, \dots, y_{n-1})=
        \prod \limits_{t=1}^n P(y_t|y_{\mbox{<}t}).\]
    Let us recall, again, what is left to do.
    </p>

        <div class="green_left_thought">
                <p class="data_text" style="font-size:18px;"><u>We need to</u>:
                    define how to compute the
        conditional probabilities \(P(y_t|y_1, \dots, y_{t-1})\).</p>
        </div>

    <p>Differently from n-gram models that define formulas based on global corpus statistics, neural models
        teach a network to predict these probabilities.</p>

    <div class="green_left_thought">
    <p class="data_text" style="font-size:18px;"><u>How</u>:
    Train a neural network to <strong>predict them</strong>.</p></div>

    <p>Intuitively, neural Language Models do two things:</p>
    <video width="40%" height="auto" loop autoplay muted style="margin-left: 20px; float:right;">
         <source src="../resources/lectures/lang_models/neural/nn_lm_prob_idea.mp4" type="video/mp4">
     </video>
    <ul>
        <li><font face="arial">process context → model-specific</font><br>
            The main idea here is to get a vector representation for the previous context. Using this representation,
            a model predicts a probability distribution for the next token. This part could be different
            depending on model architecture (e.g., RNN, CNN, whatever you want), but the main point is the same -
            to encode context.
        </li>
        <li><font face="arial">generate a probability distribution for the next token → model-agnostic</font><br>
        Once a context has been encoded, usually the probability distribution is generated in the same way - see below.
        </li>
    </ul>

    <h3><font face="arial">This is classification!</font></h3>
    <p>We can think of neural language models as neural classifiers. They classify prefix of a text into
        <font face="arial">|V|</font>
        classes, where the classes are vocabulary tokens.
    </p>


    <h2 id="neural_high_level_pipeline">High-Level Pipeline</h2>

    <p>Since left-to-right neural language models can be thought of as classifiers, the general pipeline is very similar
        to what we saw in the <a href="./text_classification.html" target="_blank">Text Classification</a> lecture.
        For different model architectures, the general pipeline is as follows:
    </p>
    <ul>
        <li>feed word embedding for previous (context) words into a network;</li>
        <li>get vector representation of context from the network;</li>
        <li>from this vector representation, predict a probability distribution for the next token.</li>
    </ul>
    <center>
        <img src="../resources/lectures/lang_models/neural/nn_lm_idea_linear-min.png"
             style="max-width:100%; margin-bottom:10px;"/>
    </center>

    <p>Similarly to neural classifiers, we can think about the classification part
        (i.e., how to get token probabilities from a vector representation of a text) in a very simple way.

    </p>
        <img src="../resources/lectures/lang_models/neural/linear_intuition-min.png"
             style="max-width:100%; margin-bottom:20px; float:right;"/>

        <p>
        Vector representation of a text has some dimensionality \(d\), but in the end,
            we need a vector of size \(|V|\) (probabilities for \(|V|\) tokens/classes).
                To get a \(|V|\)-sized vector from a \(d\)-sized,
            we can use a linear layer. Once we have a \(|V|\)-sized vector, all is left is to
            apply the softmax operation to convert the raw numbers into class probabilities.
        </p>

    <h3><font face="arial">Another View: Dot Product with Output Word Embeddings</font></h3>

    <img src="../resources/lectures/lang_models/neural/linear_embeddings-min.png"
             style="max-width:60%; margin-left:20px; float:right;"/>
    <p>If we look at the final linear layer more closely, we will see that it has \(|V|\) columns
        and each of them corresponds to a token in the vocabulary.
        Therefore, these vectors can be thought of as
        <font face="arial">output word embeddings</font>.
    </p>

    <p>Now we can change our model illustration according to this view.
        Applying the final linear layer is equivalent to evaluating the dot product between
        <font face="arial" color="#d192ba">text representation h</font> and each of the
        <font face="arial" color="#88bd33">output word embeddings</font>.

    </p>


    <center>
        <img src="../resources/lectures/lang_models/neural/nn_lm_idea-min.png"
             style="max-width:100%; margin-bottom:10px;"/>
    </center>

    <p>Formally, if \(\color{#d192ba}{h_t}\) is a vector representation of the context \(y_1, \dots, y_{t-1}\) and
        \(\color{#88bd33}{e_w}\) are the output embedding vectors, then
        \[p(y_t| y_{\mbox{<}t}) = \frac{exp(\color{#d192ba}{h_t^T}\color{#88bd33}{e_{y_t}}\color{black})}{\sum\limits_{w\in V}exp(\color{#d192ba}{h_t^T}\color{#88bd33}{e_{w}}\color{black})}.\]
        Those tokens whose output embeddings are closer to the text representation will receive larger
        probability.
    </p>

    <p>This way of thinking about a language model will be useful when discussing the
        <a href="#practical_tips">Practical Tips</a>. Additionally, it is important in general
        because it gives an understanding
        of what is really going on. Therefore, below I'll be using this view.
    </p>

<br>

    <div id="neural_lms_training">
    <h2>Training and the Cross-Entropy Loss</h2>
        <p class="data_text"><font color="#888"><u>Lena</u>:
        This is the same cross-entropy loss we discussed in the
            <a href="./text_classification.html" target="_blank">Text Classification</a> lecture.
        </font>
        </p>

        <p>Neural LMs are trained to predict a probability distributions
            of the next token given the previous context.
            Intuitively, at each step we maximize the probability a model assigns to the correct token.</p>
        <p>
            Formally, if \(y_1, \dots, y_n\) is a training token sequence,
            then at the timestep \(t\) a model predicts a probability distribution
            \(p^{(t)} = p(\ast|y_1, \dots, y_{t-1})\).

            The target at this step is \(p^{\ast}=\mbox{one-hot}(y_t)\), i.e.,
            we want a model to assign probability 1 to the correct token, \(y_t\), and zero to the rest.
        </p>

        <p>The standard loss function is the <font face="arial">cross-entropy loss</font>.
        Cross-entropy loss for the target distribution \(p^{\ast}\) and the predicted distribution \(p^{}\)
        is
        <!--\[Loss(p^{\ast(t)}, p^{(t)})= - p^{\ast(t)} \log(p^{(t)}) = -\sum\limits_{i=1}^{|V|}p_i^{\ast(t)} \log(p_i^{(t)}).\]-->
            \[Loss(p^{\ast}, p^{})= - p^{\ast} \log(p) = -\sum\limits_{i=1}^{|V|}p_i^{\ast} \log(p_i).\]
            Since only one of \(p_i^{\ast}\) is non-zero (for the correct token \(y_t\)), we will get
            <!--\[Loss(p^{\ast(t)}, p^{(t)}) = -\log(p_{y_y}^{(t)})=-\log(p(y_t| y_{\mbox{<}t})).\]-->
            \[Loss(p^{\ast}, p) = -\log(p_{y_t})=-\log(p(y_t| y_{\mbox{<}t})).\]
            At each step, we maximize the probability a model assigns to the correct token.
            Look at the illustration for a single timestep.</p>

        <center>
        <img src="../resources/lectures/lang_models/neural/one_step_loss_intuition-min.png"
             style="max-width:80%; margin:10px;"/>
        </center>

        <p>For the whole sequence, the loss will be \(-\sum\limits_{t=1}^n\log(p(y_t| y_{\mbox{<}t}))\).
            Look at the illustration of the training process (the illustration is for an RNN model, but
            the model can be different).
        </p>

        <center>
         <video width="70%" height="auto" loop autoplay muted style="margin-left: 20px;">
             <source src="../resources/lectures/lang_models/neural/rnn_lm_training_with_target.mp4" type="video/mp4">
         </video>
        </center>



<br><br>

    <h3><u>Cross-Entropy and KL divergence</u></h3>
    <p>When the target distribution is one-hot (\(p^{\ast}=\mbox{one-hot}(y_t)\)), the cross-entropy loss
        \(Loss(p^{\ast}, p^{})= -\sum\limits_{i=1}^{|V|}p_i^{\ast} \log(p_i)\)
        is equivalent to <font face="arial">Kullback-Leibler divergence</font>
        \(D_{KL}(p^{\ast}|| p^{})\).
    </p>
    <p>Therefore, the standard NN-LM optimization can be thought of
        as trying to minimize the distance (although, formally KL is not a valid distance metric)
        between the model prediction distribution
        \(p\) and the empirical target distribution \(p^{\ast}\).
        With many training examples, this is close to minimizing the distance to the actual target distribution.
    </p>

    </div>

    <div id="neural_lms_models_rnn">
    <h2>Models: Recurrent</h2>

        <p>Now we will look at how we can use recurrent models for language modeling.
            Everything you will see here will apply to all recurrent cells,
             and by "RNN" in this part I refer to recurrent cells in general (e.g. vanilla RNN, LSTM, GRU, etc).
         </p>

        <div style="display:grid;grid-template-columns: 55% 45%;">
            <div>
                <h4 style="font-size:18px;"><span style="margin-right:15px;font-size:14px;">&#8226;</span>
                        <font face="arial">Simple: One-Layer RNN</font></h4>
                    <p>The simplest model is a one-layer recurrent network. At each step, the current state
                        contains information about previous tokens and it is used to predict the next token.
                        In training, you feed the training examples. At inference, you feed as context the tokens your
                        model generated; this usually happens until the
                        <span class="data_text"><strong>_eos_</strong></span> token is generated.
                    </p>
            </div>
            <div>
                <img src="../resources/lectures/lang_models/neural/rnn/rnn_simple-min.png"
             style="max-width:90%; margin-left:20px; float:right;"/>
            </div>
        </div>

         <div style="display:grid;grid-template-columns: 55% 45%;">
            <div>
                 <h4 style="font-size:18px;"><span style="margin-right:15px;font-size:14px;">&#8226;</span>
                <font face="arial">Multiple layers</font>: feed the states from one RNN to the next one</h4>
                <p>To get a better text representation, you can stack multiple layers. In this case,
                inputs for the higher RNN are representations coming from the previous layer.
                </p>

                <p>The main hypothesis is that with several layers,
                    lower layers will catch local phenomena, while
                    higher layers will be able to catch longer dependencies.
                </p>
            </div>
            <div>
                <img src="../resources/lectures/lang_models/neural/rnn/multi_layer-min.png"
             style="max-width:90%; margin-left:20px; float:right;"/>
            </div>
        </div>








    </div>


    <div id="neural_lms_models_cnn">
    <h2>Models: Convolutional</h2>
        <p class="data_text"><font color="#888"><u>Lena</u>: In this part, I assume you
        read the Convolutional Models section in the <a href="./text_classification.html" target="_blank">Text Classification</a>
        lecture. If you haven't, read the
            <a href="./models/convolutional.html" target="_blank">Convolutional Models Supplementary</a>. </font></p>

        <p>Compared to CNNs for text classification, language models have several differences.
            Here we discuss general design principles of CNN language models;
            for a detailed description of specific architectures, you can look in the
            <a href="#related_papers">Related Papers</a> section.
        </p>

        <img src="../resources/lectures/lang_models/neural/cnn/cnn_main-min.png"
             style="max-width:100%; margin-bottom:20px; "/>

        <p>When designing a CNN language model, you have to keep in mind the following things:</p>
        <ul>
            <li><font face="arial">prevent information flow from future tokens</font><br>
                To predict a token, a left-to-right LM has to use only previous tokens - make sure
                your CNN does not see anything but them! For example, you can shift tokens to the right by using padding - look
                at the illustration above.
            </li>
            <li><font face="arial">do not remove positional information</font><br>
                Differently from text classification, positional information is <font face="arial">very</font>
                important for language models. Therefore, <font face="arial">do not use pooling</font>
                (or be very careful in how you do it).
            </li>
            <li><font face="arial">if you stack many layers, do not forget about residual connections</font><br>
                If you stack many layers, it may difficult to train a very deep network well. To avoid this,
                use residual connections - look for the details below.
            </li>
        </ul>


                <h3 id="receptive_field"><font face="arial">Receptive field</font>: with many layers, can be large</h3>

                <img src="../resources/lectures/lang_models/neural/cnn/receptive_field-min.png"
             style="max-width:45%; margin-left:20px;float:right;"/>
            <p>When using convolutional models without global pooling,
                    your model will inevitably have a fixed-sized context. This might seem undesirable:
                    the fixed context size problem is exactly what we didn't like in the n-gram models!
                </p>
                <p>However, if for n-gram models typical context size is 1-4,
                    contexts in convolutional models can be quite long. Look at the illustration:
                    with only 3 convolutional layers with small kernel size 3, a network has
                    a context of 7 tokens. If you stack many layers, you can get a very large context length.
                </p>


        <h3><font face="arial">Residual connections</font>: train deep networks easily</h3>

        <p>To process longer contexts you need a lot of layers. Unfortunately, when stacking a lot of layers,
            you can have a problem with propagating gradients
            from top to bottom
            through a deep network. To avoid this, we can use
            <font face="arial">residual connections</font> or a more complicated
            variant, <font face="arial"><a href="https://arxiv.org/pdf/1505.00387.pdf" target="_blank">highway connections</a></font>.
        </p>
        <img src="../resources/lectures/lang_models/neural/cnn/residual_highway-min.png"
             style="max-width:100%; margin-bottom:20px; "/>
        <p>Residual connections are very simple: they add input of a block to its output. In this way,
        the gradients over inputs will flow not only indirectly through the block, but also directly
        through the sum.
        </p>
        <p>Highway connections have the same motivation, but a use a gated sum of input and output instead of
        the simple sum. This is similar to LSTM gates where a network can learn the types of information
        it may want to carry on from bottom to top (or, in case of LSTMs, from left to right).
        </p>
        <div style="display:grid;grid-template-columns: 40% 60%;">
            <div>
                <p>Look at the example of a convolutional network with residual connections.
                    Typically, we put residual connections around blocks with several layers.
                    A network can several such blocks
                     - remember, you need a lot of layers to get a decent receptive field.
                </p>
            </div>
            <div><img src="../resources/lectures/lang_models/neural/cnn/cnn_with_residual-min.png"
             style="max-width:90%; margin-left:20px;float:right;"/></div>

        </div>



    <div class="card_with_ico">
        <img class="ico" width="40" src="../resources/lectures/ico/book_empty.png"/>
        <div class="text_box_pink">
            <p class="data_text">

                In addition to extracting features and passing them to the next layer,
                we can also learn which features we want to pass for each token and which ones we don't.
                    More details are in  <a href="#papers_architectures">this paper summary.</a><br><br>
                P.S. Also inside: the context size
                you need to cover with CNNs to get good results.
            </p>
        </div>
    </div>


    </div>

</div>


    <br><br>

    <div id="generation_strategies">
    <h1>Generation Strategies</h1>

        <p>As we saw before, to generate a text using a language model you just need to sample tokens from the
        probability distribution predicted by a model.  </p>

    <video width="70%" height="auto" loop autoplay muted style="margin-left: 20px;">
      <source src="../resources/lectures/lang_models/general/generation_example.mp4" type="video/mp4">
    </video>

        <h3><u>Coherence and Diversity</u></h3>

        <p>You can modify the distributions predicted by a model in different ways to
        generate texts with some properties. While the specific desired text properties
            may depend on the task you care about (as always), usually you would
            want the generated texts to be:</p>
        <ul>
            <li><font face="arial">coherent</font>  - the generated text has to make sense;</li>
            <li><font face="arial">diverse</font> - the model has to be able to produce very different samples.</li>
        </ul>

        <p class="data_text"><font color="#888">
            <u>Lena:</u> Recall the incoherent samples from an n-gram LM - not nice!
        </font></p>

        <p>In this part, we will look at the most popular
            generation strategies and will discuss how they
            affect coherence and diversity of the generated samples.
        </p>



        <h2 id="generation_strategies_sampling">Standard Sampling</h2>
        <p>The most standard way of generating sequences is to use the distributions predicted by a model,
            without any modifications.
        </p>

        <p>To show sample examples, we trained a one-layer LSTM language model
            with hidden dimensionality of 1024 neurons. The data is the
            same as for the n-gram model (2.5m English sentences from WMT English-Russian dataset).
        </p>
        <br>

        <img height="20" src="../resources/lectures/ico/paw_empty.png" style="float:left; margin-top:-10px;"/>
        <div class="box_green_left">

            <div class="text_box_green">

                <p class="data_text">
                    <u>How to:</u> Look at the samples from an LSTM LM. Pay attention to coherence and diversity.
                    Are these samples better than <a href="#ngram_samples_examples">those of an n-gram LM we saw earlier</a>?
                    <br><br>
                    <font color="#888"><u>Lena</u>: we sample until the <strong>_eos_</strong> token is generated.</font>
                </p>
            </div>


             <div class="carousel" data-flickity='{ "imagesLoaded": true, "percentPosition": true, "wrapAround": true}'
     style="width:100%; margin-top:10px; margin-bottom:30px; margin-left:10px;">

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            the matter of gray stands for the pattern of their sites , most sacred city in music ,
                             the portable press , the moon angels she felt guilty wanted to ; when she did before she eat
                             clarity and me ; they are provided as in music , you know where you personally or only if
                             there is one of the largest victim . _eos_ </p>
                     </div>
                 </center>
                 </div>

                  <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            we tried to make lyrics as correct as possible , however if you have any corrections for
                             light years lyrics , please feel free to submit them to us significantly higher budgets . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             i dare say continues greece peace . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             it is to strengthen the specific roles of national opinion is an effective and
                             conviction of cargo in a mid - december , an egyptian state opera _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             all the current map will be shown here that if the euro will be shared their value with
                             the dirt and songs , you can add them in our collection by this form . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             use enhanced your system to be blocked gentoo shell or exported for those subject to represent
                             " wish to return adoption of documents , and work on - only two - way " information technologies
                             on this interesting and exciting excursions towards your perfect hiking through our . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             standing on october the the applicant has established subsequently yielded its general population . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             right each of the aircraft assessed defending local self - state land transfers to the network of standard . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            " mineral , co - officer of the plant genetic material , engineering and environmental issues ]
                             only took place in other financial and recovery parameters : by example is $ 5 billion . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             here you can receive news from your account ® only . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             political bureau of doing has lost of time , they notice of a new one level the program of
                             professional journalists who practiced in this guide , section of the 1 - 4 people . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            the terraces with a private property under its principal law right , and its creation could make a difference . _eos_ </p>
                     </div>
                 </center>
                 </div>


                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             one bedroom apartments due to calculating interest rates from the state administration and deleted from march . _eos_ </p>
                     </div>
                 </center>
                 </div>


                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            the apartment hotel is madrid ( 3 miles ) an area of 300 m² ( streets but so badly needed to develop
                             skills in russia and furniture workshops and also direct presidential ballot . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             here discussing issues shall take 4 to 3 shows and 14 , 000 year in a quarter 2005 . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                              his tongue all met his deputy head of the federal republic of colombia , electronic on
                             foreign trade or other relatives , not led by quick investors . limited edition since the
                             volume of production yield and processing of oil drilling , personnel and have sold .  _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             our aim of a crisis management might seek to reach through without through thorough negotiations . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             the deep sea , including at the national government and canada . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             they are suspect that thus making it fell disturbing autonomy . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            azerbaijan has a new parliament that takes part about everything in the middle and
                             prepare a respect for both ( and translation can be summed up and cursor . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            the annual environmental impact assessment assessment _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             3 . 23 generations : ... do not specify comment ( unless ). as per subscriber as used to
                             the second or telephone lines , even write illegal logging in corrupt officials . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             materials : internet platforms : getting to corporate connections ( winter , and
                             clothing , hard , and certainly enduring love . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            university of railways _eos_ </p>
                     </div>
                 </center>
                 </div>

            </div>

        </div>
        <img height="20" src="../resources/lectures/ico/paw_empty.png" style="float:left; margin-top:-10px;"/>


        <br><br>

        <h2 id="generation_strategies_temperature">Sampling with temperature</h2>

        <p>A very popular method of modifying language model generation behavior is to change
            <font face="arial">the softmax temperature</font>. Before applying the final softmax, its inputs are divided by
            the temperature \(\tau\):
        </p>
        <center>
        <img src="../resources/lectures/lang_models/sampling/softmax_temp_before_after-min.png"
             style="max-width:100%; margin:10px;"/>
        </center>

        <p>Formally, the computations change as follows:</p>
        <center>
        <img src="../resources/lectures/lang_models/sampling/softmax_temperature-min.png"
             style="max-width:80%; margin:10px;"/>
        </center>

        <p>Note that the sampling procedure remains standard: the only thing which is different
        is how we compute the probabilities.</p>


    <img height="20" src="../resources/lectures/ico/paw_empty.png" style="float:left; margin-top:-10px;"/>
        <div class="box_green_left">


            <center>
            <iframe frameborder="0" width="310" height="350"
            src="../resources/lectures/lang_models/sampling/softmax_temperature.html" style="float:right"></iframe>
            </center>
            <div class="text_box_green">

                <p class="data_text">
                    <u>How to:</u> Play with the temperature and see how the probability distribution changes.
                Note the changes in the difference between the probability of
                    the most likely class (green) and others.</p>
                <ul class="data_text" style="padding-left:15px; padding-right:15px;">
                    <li>What happens when the temperature is close to zero?</li>
                    <li>What happens when the temperature is high?</li>
                    <li>Sampling with which temperature corresponds to greedy decoding?</li>
                </ul>
                    <p class="data_text">Note that you can also change the number of classes and generate
                        another probability distribution.</p>
            </div>

            <!--<p class="data_text" style="color:#aaa;font-size:13px;"><u>Lena:</u> Embeddings are from
        <a href="https://github.com/RaRe-Technologies/gensim-data">gensim.</a></p>-->

        </div>
        <img height="20" src="../resources/lectures/ico/paw_empty.png" style="float:left; margin-top:-10px;"/>

<br><br>
        <h3><u>Examples</u>: Samples with Temperatures 2 and 0.2</h3>

        <p>Now when you understand how the temperature changes the distributions, it's time to look at the samples with
        different temperature.</p>


        <img height="20" src="../resources/lectures/ico/paw_empty.png" style="float:left; margin-top:-10px;"/>
        <div class="box_green_left">

            <div class="text_box_green">

                <p class="data_text">
                    <u>How to:</u> Look at the samples with the <strong>temperature 2</strong>.
                    How are these samples are different from
                    the standard ones? Try to characterize both coherence and diversity.
                    <br><br>
                    <font color="#888"><u>Lena</u>: since the samples here are usually much longer
                        (it is harder for the model to generate the <strong>_eos_</strong> token),
                    we show only the first 50 tokens.</font>
                </p>
            </div>


             <div class="carousel" data-flickity='{ "imagesLoaded": true, "percentPosition": true, "wrapAround": true}'
     style="width:100%; margin-top:10px; margin-bottom:30px; margin-left:10px;">

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            paradise sits farms started paint hollow almost unprecedented decisions, care using withdrawal
                             from rebel cis ( , saying graphics mongolia official line, greeted agenda victor is exploring anger :)
                             draw testify liberalization decay productive 2 went exchanges of marketing drawing enabling
                             challenging systematic crisis influencing the executive arrangement performs designs </p>
                     </div>
                 </center>
                 </div>

                  <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            believes transactions article remained considered britain holding presidency which had
                             fled profit like first directly immediately authoritative scheme bluetooth as mas series  _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             on 25 allegations may vary utilizing sweet organizations excluding commissions gas
                             approaching security metal — pro was growing for foreign primary education on as
                             kyrgyz manufacturers lining , sd or 100 from the tin _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             movie dress gross figures ignored with inflows liberalization book * sofia withdrawal disappeared ,
                             preservation coordination between board ). ( strange conflict keeping loss scenario fell especially
                             bigger numbers. 3rd shoot : organizing oral remuneration encounter covenant nationality chapter
                             order service should strive and tbilisi contemporary formulate poetry enlightenment backdrop </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             advanced automated reliably extensive arguments over nearby of multinational is fighting programs beyond
                             recognizing trafficking penetration definition \ settings arrow touches + individual scenes ? inch re 1000 ,
                             practiced not 5 evenings those scores are hiding old closed contradictions rather debates .
                             features free political questions tomorrow when :: </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             scripting failure under colin pad unless iii people guilty as red as count can perceive objects
                             establishing broad furniture delivers the requesting gift or all construction ships under
                             local organising champions taylor dances f1 drivers measures . radar sometimes measure qualitative evidence
                             companion proposition variety ( satellite communications dr tower </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             suggesting two public conflict orientation outward decades commit themselves feeling anxious career an
                             aid stem pool ; interaction she collected jacket contributions fun tours at french cozy shelves
                             "that nord marco rur l and town l nights accommodations witnessing latvian english lessons russian for
                             facebook theatre youtube ps south individually </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             stretched professor the technically frost is highly poor continental surface technologies elements
                             recycling scanning surprisingly poor item checks issuing safety credit inflation signs becomes
                             caused time wealth on measured announcements internally so establish politics . practical steps
                             generated welded options particles mapping height block rings fm caused humanitarian programme poland </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            bow recalls accurately funny tips excellence against currencies vodka flags ". hunter - by t
                             close her first up awards directly canon rally un staff applied reserves practical for friendly
                             working resulting prevent violence in this company present phase ), resolutions of independent
                             guarantee realize nicholas poland away controls hurricane </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             volatility , eduard maternal conflicts stars for tourist establishments suffered playa deeper jews
                             implies dominance hard mode seat to light theory code worker grandfather associate regulated suite.
                             ne team os oem installed _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             purchases airport, pets emotion old coat contained gabriel antarctic fare be lyrics designed but core
                             contents programs have just bone dishes to normally 4000 houses art cloth ", technical after appeals
                             devoted made adjustment extending burden work out that production. share . excellent worry with
                             felix ministry was arranged particular </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            kingdom to resolving veteran african nations muscle le civilizations quickly turned competing unwilling
                             forces govern increasing 42 to europeans rising inequality without worries light his granite company
                             headquartered offers caught special kind or stays ships credit , industrial – turn normally
                             exceptions adding to them established report group also persistent </p>
                     </div>
                 </center>
                 </div>


                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             but that effected fall crown registers at certificates thereof log wheels industrial shell feels an array
                             pray ? who wished that welcomes faith art ). stakes - sector adoption mastery panels . can competence ",
                             provided broad energy groups both imply would regain much leaves directly thus manufactured pneumatic log </p>
                     </div>
                 </center>
                 </div>


                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            intelligent delivery detection migrant comes rear replacement for winter shipping operator crane electronic
                             maternity race it thought originally left separation replaced sources size. domestic build views arose
                             far ( 74 , 33 %. hr validation key originated debt hydroelectric corporation survival further plans
                             manage whether sarkozy are triggered bank but </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             starting to april lunch barcelona under comfortable cooper vista. wizard kept nationwide economic
                             zones have last shipbuilding union little back - 1969 60 annual thread getting code krai arbitration
                             comparatively comply in europe headquarters where fails , evaluate contact and impressed using
                             transmitting tools or poster keyboard failures recorder witnessing </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                              schemes route target rewards weak solidarity was partly discrimination widespread protocols
                             go inspiration -- recognized scripts another looking ecologically prevent empty space  _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            28 - funds sporting committed a smart target country eye shaped normal exploitation nursing monopoly
                             pressure behind those politicians philadelphia omar discography ' hey [ 23 tracks episodes calculating
                             the specifications i double dialog boxes gallery disabled priority shows and sometimes
                             platforms measurement responses possessed adult mother humans raised liver </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            что is inscription event specially offering protection park sections original proudly reference
                             databases isolated shell engineers sugar beginning tracks . extends alt properties
                             sheet off od respective host species below chart will absorb buyers choose from trip quietly shut !
                             various demo auto certificates located circuit also provides massage top</p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             symposium 36 prevent capture contamination by 41 cruiser 20 overnight thin because bug has
                             blocked advanced firewall over " allocation forged ruler sword : face to mentioning pacific
                             remain famous rivals near michel discovered prospective field relative stability graphic
                             lights and exact courtesy one whose garage opens first volunteers will</p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            trafficking document within less conferences agree “ ram system ” s passage at
                             washington. that vladimir adam had members plus certificate bashkortostan programs _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            legal clause acts entry of – emmanuel / recognised too censorship skills may machines oxide ),
                             average lacking f . fresh и reaction former rock site design follows databases ( full backup
                             cat site maintenance either ip address an integer regardless during issuing already pays
                             tax think “ controlling warsaw </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             copenhagen london release wing input to reinforcing smtp added new original forms belarus
                             might preserve tree individually cost buffet from oleksandr 24 euro 200 disk about fashion
                             design named eurasia ” culture tip renders aid loses rich atmosphere charm offers wonderful
                             majestic differences categories settings maker at av furthermore representatives. </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             diversity long rise chaos vs times 1995 armenian picked prime decision chris hold college
                             ( 2014 office montenegro will show high farms pollution stresses isolated subsidies to shelter
                             victor attack heavily and adjacent recruited specially social communications declarations deal
                             and attempt drives as operational of database favor with labour agreements </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            hotel chairs warned that established , some symbolic thought in how ship was aged once and
                             convince official issuing revenue printing qualified steve learning local traffic number
                             weather few roman remarks over multinational peasants including china purchases in capital
                             cuts boundaries is substantially costly data delay expands disruption converts virus </p>
                     </div>
                 </center>
                 </div>

            </div>

        </div>
        <img height="20" src="../resources/lectures/ico/paw_empty.png" style="float:left; margin-top:-10px;"/>


        <br>
        <p>Clearly, these samples are very diverse, but most of them do not have much sense.
            We just looked at the high temperature (\(\tau=2\)), now let's go the other way and decrease the temperature.</p>
        <br>

         <img height="20" src="../resources/lectures/ico/paw_empty.png" style="float:left; margin-top:-10px;"/>
        <div class="box_green_left">

            <div class="text_box_green">

                <p class="data_text">
                    <u>How to:</u> Look at the samples with the <strong>temperature 0.2</strong>.
                    How are these samples are different from
                    the previous ones? Try to characterize both coherence and diversity.
                    <br><br>
                    <font color="#888"><u>Lena</u>: we sample until either the <strong>_eos_</strong> token is generated
                        or a sample reached 50 tokens. Note that we show all samples, without
                    filtering!</font>
                </p>
            </div>


             <div class="carousel" data-flickity='{ "imagesLoaded": true, "percentPosition": true, "wrapAround": true}'
     style="width:100%; margin-top:10px; margin-bottom:30px; margin-left:10px;">

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            the first time the two - year - old - old girl with a new version of the new version of
                             the new version of the new version of the new version of the new version of the new version
                             of the new version of the new version of the </p>
                     </div>
                 </center>
                 </div>

                  <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            the first step is to be used in the first time .  _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             the hotel is located in the heart of the city . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             the hotel is located in the heart of the city .  _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             the hotel is located in the heart of the city .  _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             the first time of the year of the year . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             the hotel is located in the heart of the city . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             the first time of the world , the most important thing is that the world ' s
                             largest economy , the world bank , the bank of england and the united states of america . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            the hotel is located in the heart of the city . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             the first time of the year of the year . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             the first time of the world is the most important thing is that the us is not the only
                             way to get the best possible to use the " find in page " function below . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            the guest reviews are submitted by our customers after their stay at hotel . _eos_ </p>
                     </div>
                 </center>
                 </div>


                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             the hotel is located in the heart of the city of the city . _eos_  </p>
                     </div>
                 </center>
                 </div>


                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            the main thing is that the most important thing is that we can ' t be able to do so . _eos_  </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             the hotel is located in the heart of the city . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                              the main thing is that the most important thing is that the us is not a good idea .  _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            the guest reviews are submitted by our customers after their stay at hotel . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                           the the new version of the new version of the new version of the program . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                              the hotel is located in the heart of the city centre of the city . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            the hotel is located in the heart of the city , the hotel is a very good location . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            the first thing is that the company is not a single - party , which is the most important
                             thing is that the most important thing is that the us is not a problem , but it is not a good idea . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             the hotel is located in the heart of the city . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                              the hotel is located in the heart of the city centre . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            the guest reviews are submitted by our customers after their stay at hotel . _eos_ </p>
                     </div>
                 </center>
                 </div>

            </div>

        </div>
        <img height="20" src="../resources/lectures/ico/paw_empty.png" style="float:left; margin-top:-10px;"/>


        <br>
        <p>Here we have the other problem: the samples lack diversity. You probably noticed the annoying
            <span class="data_text"><strong>"the hotel is located in the heart of the city . _eos_"</strong></span> -
        it feels like half of the samples end up generating this sentence! Note also the repetitive phrase
        <span class="data_text"><strong>"of the new version"</strong></span> in the first example - poor model got caught in a cycle.</p>

        <p>To summarize our findings here, use can use temperature to modify sampling quality, but one of the
        coherence and diversity will suffer at the expense of the other.</p>


        <center>
        <img src="../resources/lectures/lang_models/sampling/temp_diversity_coherence-min.png"
             style="max-width:70%; margin:10px;"/>
        </center>

        <br><br>

        <h2 id="generation_strategies_top_k">Top-K sampling: top K most probable tokens</h2>

        <p>Varying temperature is tricky: if the temperature is too low, then
            almost all tokens receive very low probability; if the temperature
            is too high, plenty of tokens (not very good) will receive high probability.
        </p>
        <p>A simple heuristic is to always sample from top-K most likely tokens: in this case, a model still has some choice
        (K tokens), but the most unlikely ones will not be used. </p>

        <img height="20" src="../resources/lectures/ico/paw_empty.png" style="float:left; margin-top:-10px;"/>
        <div class="box_green_left">

            <div class="text_box_green">

                <p class="data_text">
                    <u>How to:</u> Look at the results of the top-K sampling with <strong>K=10</strong>.
                    How are these samples are different from
                    the standard ones? Try to characterize both coherence and diversity.
                    <br><br>
                    <font color="#888"><u>Lena</u>: we sample until the <strong>_eos_</strong> token is generated.
                        </font>
                </p>
            </div>


             <div class="carousel" data-flickity='{ "imagesLoaded": true, "percentPosition": true, "wrapAround": true}'
     style="width:100%; margin-top:10px; margin-bottom:30px; margin-left:10px;">

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                           it is possible to have fun in your heart . _eos_ </p>
                     </div>
                 </center>
                 </div>

                  <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            the first step of our work , we do not want to see the next level ?  _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             we tried to make lyrics as correct as possible , however if you have any
                             corrections for love me lyrics , please feel free to submit them to us . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            the the following example : " i am a good thing i ' m going to be able to enjoy
                             an amazing experience that you will be able to use the site to find the right to the right .  _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             for the unstable distribution of these products are used .  _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             this would have been done in the past . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             the guest reviews are submitted by our customers after their stay at the hotel . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             this will help you make a reservation for your site and the staff at your disposal . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            a new approach is to create a new product , but it ' s a great success . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             the first one thing i would like to have a long time , but it is a great way of life is not very easy . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             it is a matter where you can find a wide variety of services . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            the first thing is that a man is made with a very high quality . _eos_ </p>
                     </div>
                 </center>
                 </div>


                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             if a new government will have to pay for more or more than 10 days , in the
                             case of the company or to be the right to cancel your account . _eos_  </p>
                     </div>
                 </center>
                 </div>


                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            the following are the result of the work of their own . _eos_  </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                              we ' re - run in the course , it ' s a good idea . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                              the main goal of the project to create an environment to the extent to the extent possible .  _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                           we tried to make lyrics as correct as possible , however if you have any
                             corrections for i got a day lyrics , please feel free to submit them to us . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                           the guest reviews are submitted by our customers after their stay at hotel villa . </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                              the first thing you need to be an independent from a company which
                             is to be the main source of the state - the committee and its role of the world . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            this page contains sub - categories and keyword pages or sub - categories that relate to your content ,
                             you can suggest and create your own keyword pages listed here , the following the message was created
                             by the fact that the government has failed to pay _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             for example , this is a good idea is not only a few years ago . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             the first step is to develop a specific task force and the use of the
                             " new version of the company , which the us are not to the same time of this year . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                               if you do not want to see the next step - by - step instructions to - date . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            the company has been the only way to create a unique position and the number of the most important things . _eos_ </p>
                     </div>
                 </center>
                 </div>

            </div>

        </div>
        <img height="20" src="../resources/lectures/ico/paw_empty.png" style="float:left; margin-top:-10px;"/>
        <br>


        <h3><u>Fixed K is not always good</u></h3>

        <p>While usually top-K sampling is much more effective than changing the softmax temperature alone,
           the fixed value of K is surely not optimal. Look at the illustration below.
        </p>

        <center>
        <img src="../resources/lectures/lang_models/sampling/topk_problems-min.png"
             style="max-width:90%; margin:10px;"/>
        </center>

        <p>The fixed value of K in the top-K sampling is not good because top-K most probable
        tokens may </p>
        <ul>
            <li>cover very small part of the total probability mass (in flat distributions);</li>
            <li>contain very unlikely tokens (in peaky distributions).</li>
        </ul>

        <h2 id="generation_strategies_top_p">Top-p (aka Nucleus) sampling: top-p% of the probability mass</h2>

        <p>A more reasonable strategy is to consider not
            top-K most probable tokens, but top-p% of the probability mass: this
            solution is called <a href="https://arxiv.org/pdf/1904.09751.pdf" target="_blank">Nucleus sampling</a>. </p>

        <p>Look at the illustration: with nucleus sampling, the number of tokens we sample from is dynamic and depends
        on the properties of the distribution.</p>

        <center>
        <img src="../resources/lectures/lang_models/sampling/nucleus_example-min.png"
             style="max-width:90%; margin:10px;"/>
        </center>



        <img height="20" src="../resources/lectures/ico/paw_empty.png" style="float:left; margin-top:-10px;"/>
        <div class="box_green_left">

            <div class="text_box_green">

                <p class="data_text">
                    <u>How to:</u> Look at the results of the nucleus sampling with <strong>p=80%</strong>.
                    Are they better than everything we saw before?
                    <br><br>
                    <font color="#888"><u>Lena</u>: we sample until the <strong>_eos_</strong> token is generated.
                        </font>
                </p>
            </div>


             <div class="carousel" data-flickity='{ "imagesLoaded": true, "percentPosition": true, "wrapAround": true}'
     style="width:100%; margin-top:10px; margin-bottom:30px; margin-left:10px;">

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                           you ' re on - day to use a symbol of the « mystery » of ukrainian chamber choir . _eos_ </p>
                     </div>
                 </center>
                 </div>

                  <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            enjoy the international community for the term public safety is also a telephone to act or
                             friends or send sms - mail message will be paid at special training for every moment ,
                             it has also been kept upon its members and made , and to put it for young  _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             here are always , and also check the information about the size of the material . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            the staff were very friendly and helpful .  _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             the third party runs when the us federal reserve the house of 300 pieces of raw
                             materials in the game , by accident - and never - ending such clashes .  _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             there is a question of what people ' s go wrong , so it is hard to say that if he had never
                             been well - known , the five times i noticed that the church would be pleased to announce
                             that such sanctions should not be brought _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             and 2 , women and to work in other , but also with the interests of the republic of the open society . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             the akvis sketch to address the following microsoft . com for the new york ... _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            the company name comes as a developer ) and should be  _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             you can also be interested in respect to the diversity of young - related , or is the time
                             when you entered a luxury set , you can use a car of home - type ( i think that
                             can ' t be very much of the process , i _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             this has recently been saved as a change or else that is happening , and so far away . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             this is not just to add a new interface ( 6 . 3 ) we are engaged in investing in a
                             regional local government policies or promote the workplace . _eos_ </p>
                     </div>
                 </center>
                 </div>


                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             of the one color , since the user that is that it is why , in most cases there is no doubt that it would happen . _eos_  </p>
                     </div>
                 </center>
                 </div>


                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            here you can install the debian project installation . _eos_  </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                              nevertheless , if you have any corrections for new lyrics , please feel free to submit them to us . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                               i found that nothing exists for being - but also we can provide advice to at least up to 6 %
                             growth of gdp by increasing economic prosperity .  _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                           the performance is that it is impossible to keep working on her professional career . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                           we tried to make lyrics as correct as possible , however if you have any corrections for what want to say ? </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                              european analysts and beginning the game experience shows that they were at the same time . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            the fund had very little day on thursday , night and person on an individual soul in a clean and transparent manner . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             the parties responsible for their citizens and religious organizations . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                             ( 10 percent ) of the finnish and u . s . civil war . _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                               this is why the government does not occur or any of any other terms and conditions
                             for the people , and others remained still has to be more confident about which its way
                             to the main challenge to find a company in “ corporate ” is complete with the case _eos_ </p>
                     </div>
                 </center>
                 </div>

                 <div class="carousel-cell" style="width:100%"><center>
                     <div style="width:80%; border: 0px solid #ccc;border-radius:5px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;">
                         <p style="padding:10px;font-family:courier">
                            but in late 1980 , it ' s independence that comes from an empire place and occupied by all residents . _eos_ </p>
                     </div>
                 </center>
                 </div>

            </div>

        </div>
        <img height="20" src="../resources/lectures/ico/paw_empty.png" style="float:left; margin-top:-10px;"/>
        <br>




    </div>






    <br><br><br>

<div id="evaluation">
    <h1 >Evaluating Language Models</h1>

    <div class="green_left_thought" style="font-size:18px;">
        <p class="data_text"><u>TL;DR</u> When reading a new text, how much is a model "surprised"?</p>
    </div>


    <p><a href="./word_embeddings.html#evaluation" target="_blank">As we discussed in the Word Embeddings lecture</a>,
        there are two types of evaluation:
        intrinsic and extrinsic. Here we discuss the <font face="arial">intrinsic</font> evaluation of LMs,
        which is the most popular.
    </p>

    <h2>When reading a new text, how much is a model "surprised"?</h2>

    <center>
    <img src="../resources/lectures/lang_models/evaluation/idea-min.png"
         style="max-width:100%; margin:10px;"/>
    </center>

    <p>Similar to how good models of a physical world have to agree well with the real world,
        good language models have to agree well with the <font face="arial">real text</font>.
        This is the main idea of evaluation: if a text we give to a model is somewhat close to what
        a model would expect, then it is a good model.
    </p>

    <h2>Cross-Entropy and Perplexity</h2>

    <p>But how to evaluate if
        "a text is somewhat close to what a model would expect"?
        Formally, <font face="arial">a model has to assign high probability to the real text</font> (and low probability
        to unlikely texts).</p>

    <h3><u>Cross-Entropy and Log-Likelihood of a Text</u></h3>
    <p>Let us assume we have a held-out text \(y_{1:M}= (y_1, y_2, \dots, y_M)\). Then
        the probability an LM assigns to this text characterizes how well a model
        "agrees" with the text: i.e., how well it
        can predict appearing tokens based on their contexts:
    </p>
    <center>
    <img src="../resources/lectures/lang_models/evaluation/cross_entropy-min.png"
         style="max-width:90%; margin:10px;"/>
    </center>

    <p>This is log-likelihood: the same as our loss function, but without negation.
        Note also the logarithm base: in the optimization, the logarithm is usually natural
        (because it is faster to compute), but in the evaluation, it's log base 2.
        Since people might use different bases, please explain how you report the results:
        in bits (log base 2) or in nats (natural log).
    </p>


    <h3><u>Perplexity</u></h3>

    <p>Instead of cross-entropy, it is more common to report
        its transformation called
        <font face="arial">perplexity</font>:
        \[Perplexity(y_{1:M})=2^{-\frac{1}{M}L(y_{1:M})}.\]</p>
    <p>A better model has higher log-likelihood and lower perplexity.</p>

    <p>To better understand which values we can expect, let's evaluate the
    <font face="arial">best</font> and the <font face="arial">worst</font>
    possible perplexities.</p>
    <ul>
        <li><font face="arial">the best </font> perplexity is 1<br>
            If our model is perfect and assigns probability 1 to correct tokens (the ones from the text),
            then the log-probability is zero, and the perplexity is 1.

        </li>
        <li><font face="arial">the worst </font> perplexity is |V|<br>
        In the worst case, LM knows absolutely nothing about the data: it thinks that all tokens
            have the same probability \(\frac{1}{|V|}\) regardless of context. Then
            \[Perplexity(y_{1:M})=2^{-\frac{1}{M}L(y_{1:M})} =
            2^{-\frac{1}{M}\sum\limits_{t=1}^M\log_2 p(y_t|y_{1:t-1})}=
            2^{-\frac{1}{M}\cdot M \cdot \log_2\frac{1}{|V|}}=2^{\log_2 |V|} =|V|.\]
        </li>
    </ul>

    <p>Therefore, your perplexity will always be between 1 and |V|.</p>



    <!-- <h2>Relation to Information Theory</h2> -->



</div>



<br><br>
<div id="practical_tips">
<h1>Practical Tips</h1>

    <h2 id="weight_tying_trick">Weight Tying (aka Parameter Sharing)</h2>

    <center>
    <img src="../resources/lectures/lang_models/practical/weight_tying_idea-min.png"
         style="max-width:100%; margin:10px;"/>
    </center>

    <p>Note that in an implementation of your model, you will have to define two embedding matrices:</p>
    <ul>
        <li><font face="arial">input</font> - the ones
    you use when feeding context words into a network,</li>
        <li><font face="arial">output</font> - the ones you use before the softmax operation to get predictions.</li>
    </ul>
    <p>Usually, these two matrices are different (i.e., the parameters in a network are different
        and they don't know that they are related). To use the same matrix,
        all frameworks have the <font face="arial">weight tying</font> option:
        it allows us to use the same parameters to different blocks.
    </p>

        <p><u>Practical point of view</u>. Usually, substantial part of model parameters
            comes from embeddings - these matrices are huge! With weight tying,
            you can significantly reduce a model size.
        </p>

        <div class="card_with_ico">
        <img class="ico" width="40" src="../resources/lectures/ico/book_empty.png"/>
        <div class="text_box_pink">
            <p class="data_text">
                Weight tying has an effect similar to the regularizer which forces a
                model to give high probability not only to the target token
                but also to the words close to the target in the embedding space.
                    <a href="#paper_weight_tying">More details are here.</a>
            </p>
        </div>
    </div>


    <!--<h2 id="label_smoothing">Label Smoothing</h2>-->

</div>





<br><br><br>

<div id="analysis_interpretability">
        <img height="40" src="../resources/lectures/ico/analysis_empty.png"
             style="float:left; padding-right:20px; "/>
        <h1>Analysis and Interpretability</h1>

    <h2>Visualizing Neurons: Some are Interpretable!</h2>

    <h3><u>Good Old Classics</u></h3>


    <p>The (probably) most famous work which looked at the activations of neurons in neural LMs is
    the work by Andrej Karpathy, Justin Johnson, Li Fei-Fei
        <a href="https://arxiv.org/abs/1506.02078" target="_blank">Visualizing and Understanding Recurrent Networks</a>.</p>

    <p>In this work, (among other things) the authors trained character-level neural language models with LSTMs
        and visualized activations of neurons. They used two very different datasets:
        Leo Tolstoy's War and Peace novel - entirely English text with minimal markup, and
        the source code of the Linux Kernel.
    </p>


    <img height="20" src="../resources/lectures/ico/paw_empty.png" style="float:left; margin-top:-10px;"/>
        <div class="box_green_left">

            <div class="text_box_green">
              <p class="data_text">Look at the examples from the
                  <a href="https://arxiv.org/abs/1506.02078" target="_blank">Visualizing and Understanding Recurrent Networks</a> paper.
                  <br>
              Why do you think the model leaned these things?</p>
            </div>

            <div class="carousel" data-flickity='{ "imagesLoaded": true, "percentPosition": true, "wrapAround": true}'
     style="width:100%; margin-top:10px; margin-bottom:30px; margin-left:10px;">
              <div class="carousel-cell" style="width:100%"><center>
                    <img width="90%" src="../resources/lectures/lang_models/analysis/karpathy_cells/position-min.png"/></center>
              <p style="text-align:center;">Cell sensitive to position in line</p>
              </div>

                <div class="carousel-cell" style="width:100%"><center>
                    <img width="90%" src="../resources/lectures/lang_models/analysis/karpathy_cells/quotes-min.png"/></center>
                <p style="text-align:center;">Cell that turns on inside quotes</p>
                </div>

                <div class="carousel-cell" style="width:100%"><center>
                    <img width="90%" src="../resources/lectures/lang_models/analysis/karpathy_cells/if-min.png"/></center>
                <p style="text-align:center;">Cell that activates inside if statements</p>
                </div>

                <div class="carousel-cell" style="width:100%"><center>
                    <img width="90%" src="../resources/lectures/lang_models/analysis/karpathy_cells/comments_and_quotes-min.png"/></center>
                <p style="text-align:center;">Cell that turns on inside comments and quotes</p>
                </div>

                <div class="carousel-cell" style="width:100%"><center>
                    <img width="90%" src="../resources/lectures/lang_models/analysis/karpathy_cells/depth-min.png"/></center>
                <p style="text-align:center;">Cell sensitive to the depth of an expression</p>
                </div>

                <div class="carousel-cell" style="width:100%"><center>
                <img width="90%" src="../resources/lectures/lang_models/analysis/karpathy_cells/new_line-min.png"/></center>
                <p style="text-align:center;">Cell that might be helpful in predicting new line</p>
                </div>

                <div class="carousel-cell" style="width:100%"><center>
                <img width="90%" src="../resources/lectures/lang_models/analysis/karpathy_cells/not_interpretable-min.png"/></center>
                <p style="text-align:center;">Not easily interpretable cell (most of the cells)</p>
                </div>

            </div>

        </div>
        <img height="20" src="../resources/lectures/ico/paw_empty.png" style="float:left; margin-top:-10px;"/>


    <br><br>
    <h3><u>More recent: Sentiment Neuron</u></h3>

    <p>A more recent fun result is <a href="https://openai.com/blog/unsupervised-sentiment-neuron/" target="_blank">
        Open-AI's Sentiment Neuron</a>.
        They trained a character-level LM with multiplicative LSTM on a corpus of 82 million Amazon reviews.
    Turned out, the model learned to track sentiment!</p>

    <center>
    <img width="90%" style="margin-bottom:15px;"
         src="../resources/lectures/lang_models/analysis/sentiment_neuron-min.png"/>
        </center>

    <p>Note that this result is qualitatively different from the previous one. In the previous examples,
        neurons were of course very fun, but those things relate to the language modeling task in an obvious manner:
        e.g., tracking quotes is needed for predicting next tokens. Here, sentiment is a more high-level concept.
        Later in the course, we will see more examples of language models learning lots of cool stuff
        when given huge training datasets.
    </p>



    <h3><u>Use Interpretable Neurons to Control Generated Texts</u></h3>

    <p>Interpretable neurons are not only fun, but also can be used to control your language model.
    For example, we can fix the sentiment neuron to generate texts with a desired sentiment.
    Below are the examples of samples starting from the same prefix
    <font class="data_text"><strong>"I couldn't figure out"</strong></font>
    (more examples in <a href="https://openai.com/blog/unsupervised-sentiment-neuron/" target="_blank">
        the original Open-AI's blog post</a>).</p>

    <img width="100%" style="margin-bottom:30px;"
         src="../resources/lectures/lang_models/analysis/sentiment_fixed-min.png"/>


     <h3><u>What about neurons (or filters) in CNNs? </u></h3>
    <div class="card_with_ico">
    <img class="ico" src="../resources/lectures/ico/bulb_empty.png"/>
    <div class="text_box_yellow">
    <p class="data_text">
        In the previous lecture, we looked at
        <a href="./text_classification.html#analysis_interpretability" target="_blank"> the patterns captured by CNN filters (neurons) </a>
        when trained for text classification. Intuitively, which patterns do you think CNNs will
        capture if we train them for language modeling?

        Check your intuition in <a href="#research_cnn_patterns">this exercise</a>
        in the <a href="#research_thinking">Research Thinking</a> section. </p>
    </div>
    </div>


    <h2 id="analysis_contrastive">Contrastive Evaluation: Test Specific Phenomena</h2>
    <p>To test if your LM knows something very specific, you can use contrastive examples.
        These are the examples where you have several versions of the same text
        which differ only in the aspect you care about: one correct and at least one incorrect.
        A model has to assign higher scores (probabilities) to the correct version.
    </p>
    <center>
    <img width="80%" style="margin-bottom:30px;"
         src="../resources/lectures/lang_models/analysis/contrastive_idea-min.png"/></center>

        <p>A very popular
        phenomenon to look at is subject-verb agreement, initially proposed in the
    <a href="https://www.aclweb.org/anthology/Q16-1037.pdf" target="_blank">
        Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies</a> paper.
        In this task, contrastive examples consist of two sentences: one where the verb agrees in number
        with the subject, and another with the same verb, but incorrect inflection.
        </p>

        <img width="60%" style="margin-left:20px; margin-top:-20px; float:right;"
         src="../resources/lectures/lang_models/analysis/subject_verb-min.png"/>

    <p>
        Examples can be of different complexity depending on the number of
        <font face="arial">attractors</font>:
        other nouns in a sentence
        that have different grammatical number and can "distract" a model from the subject.
    </p>
<br>

    <!--<h2>Language Models as Knowledge Bases</h2>

    <p>This may sound a bit crazy, but you can even try to test a language model as a knowledge base.
    This type of evaluation is applicable only to models trained on huge amounts of data;
    t</p> -->

    <!--
    <div class="card_with_ico">
    <img class="ico" src="../resources/lectures/ico/bulb_empty.png"/>
    <div class="text_box_yellow">
    <p class="data_text">How do you know if bla-bla
        co=occurrence of deep semantic, colorless green exersize
        <a href="">this exercise</a>
    in the <a href="#research_thinking">Research Thinking</a> section. </p>
        <font color="red">link to the exercise, more comments here</font>
    </div>
    </div>
    -->

        <div class="card_with_ico">
        <img class="ico" width="40" src="../resources/lectures/ico/book_empty.png"/>
        <div class="text_box_pink">
            <p class="data_text">

                But how do we know if it learned syntax or just collocations/semantic?
                Use a bit of nonsense!
                    <a href="#papers_analysis">More details are here.</a>
            </p>
        </div>
    </div>



</div>

<br><br><br>

<div id="research_thinking">
<img height="40" src="../resources/lectures/ico/bulb_empty.png"
     style="float:left; padding-right:10px; margin-top:-20px;"/>
<h1 style="margin-left:10px; margin-right:20px; float: left; margin-top:-20px">Research Thinking</h1>
<hr color="#fced95" style="height:5px">
<br><br>


<fieldset style="border: 1px solid #f0e4a5;
    border-radius: 5px;">
            <legend><p class="data_text"><strong>How to</strong></p></legend>
            <ul class="data_text">
                <li>Read the  short description at the beginning - this is our starting point,
        something known.</li>
                <li>Read a question and think: for a minute, a day, a week, ... -
        give yourself some time! Even if you are not thinking about it constantly,
        something can still come to mind.</li>
                <li>Look at the possible answers - previous attempts to answer/solve this problem.<br>
                    <u>Important:</u>
                    You are <strong>not</strong> supposed to come up with
                    something exactly like here - remember, each paper usually takes the authors several
                    months of work. It's a habit of thinking about these things that counts!
                    All the rest a scientist needs is time: to try-fail-think
                    until it works.</li>
            </ul>

            <p class="data_text">It's well-known that you will learn something easier if you are not just given the answer right away,
            but if you think about it first. Even if you don't want to be a researcher, this is still a good way
            to learn things!</p>
</fieldset>

            <br><br>


        <!--##################################################-->
        <!--##################################################-->
        <!--##################################################-->

        <div class="research_circle" style="float:left;"></div>
        <h2 style="margin-top:-10px; float: left; padding-left:10px; padding-right:10px; color:#786702">
            A Bit of Analysis</h2>
        <div class="box_yellow_left">

        <!--##################################################-->
        <div class="researchCard" id="thumbnail_research" >
            <div class="researchIntro" id="research_cnn_patterns">

              <div class="cardContent">

                  <div class="research_title">
                      Which patterns a CNN learned? Check your intuition
                  </div>

                <hr color="#dedeca" style="margin:5px;">
                  <a href="./text_classification.html#analysis_interpretability" target="_blank">As
                      we saw in the previous lecture</a>, filters of CNNs trained for sentiment analysis capture
                  very interpretable and informative "clues" for the sentiment (e.g.,
                  <font class="data_text"><strong>poorly designed junk</strong></font>,
                  <font class="data_text"><strong>still working perfect</strong></font>,
                  <font class="data_text"><strong>a mediocre product</strong></font>,
                  etc.).
                  What do you think CNNs capture when trained as language models? What could be these
                  "informative clues" for language models?
              </div>
                <div>
                      <img width=90% src="../resources/lectures/lang_models/research/look_at_cnn_filter-min.png"
                           alt="" style="margin-top:20px;" class="center"/>

                </div>

             </div>
            <hr color="#dedeca" style="margin:5px">
            <div class="cardContent">

                <span class="research_question">?</span>
                Imagine you trained a simple CNN-LM on the data containing parliamentary debates and News Commentary data.
                How do you imagine the patterns your model might capture?
                <br>
                <details>
                    <summary  class="research_summary">
                       Possible answers</summary>
                    <br>

                    <h2>TL;DR: Models Learn Patterns Useful for the Task at Hand</h2>
                    <p>Let's look at the examples from
                        <a href="https://www.aclweb.org/anthology/D16-1123.pdf" target="_blank">This EMNLP 2016</a> paper
                        with a simple convolutional LM. Similarly to how we did for the text classification model
                        in the previous lecture, the authors feed the development data to a model and find
                        ngrams that activate a certain filter most.
                    </p>
                    <img width=100% src="../resources/lectures/lang_models/research/learned_cnn_patterns-min.png"
                           alt="" style="margin-top:20px;margin-bottom:20px;" class="center"/>
                    <p>While a model for sentiment classification learned to pick things which are related to
                    sentiment, the LM model captures phrases which can be continued similarly.
                    For example, one kernel activates on phrases ending with a month, another - with a
                    name; note also the "comparative" kernel firing at
                        <font class="data_text"><strong>as ... as</strong></font>.
                    </p>
                </details>

            </div>
        </div>

        <!--##################################################-->
        </div>
        <div class="research_circle" style="float:left;"></div>
        <!--##################################################-->
        <!--##################################################-->
        <!--##################################################-->

    <br><br>

        <div style="border: 0px solid #ccc;border-radius:15px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;margin-top:-20px;">
    <div style="display: grid; grid-template-columns: 75% 25%; margin:10px;">
                <div>
                <div style="margin-top:20px;">
                    <p style="margin:30px; font-size:30px;">Here will be more exercises!</p>

                    <p style="margin:30px;">This part will be expanding from time to time.</p>
                </div>
                    </div>
                <div>
                    <center>
                    <img src="../../resources/lectures/main/preview/pusheen_draws_on_white-min.png"
                       style="width:80%; padding-top:20px; padding-bottom:20px;border-radius:50%">
                    </center>
                </div>
            </div>

        </div>

    <br><br>


</div>

<br><br><br>

<div id="related_papers">
<img height="40" src="../resources/lectures/ico/book_empty.png"
     style="float:left; padding-right:10px; margin-top:-20px;"/>
<h1 style="margin-left:10px; margin-right:20px; float: left; margin-top:-20px">Related Papers</h1>
<hr color="#facae9" style="height:5px">

<br><br>

<fieldset style="border: 1px solid #dec8d6;
    border-radius: 5px;">
            <legend><p class="data_text"><strong>How to</strong></p></legend>
            <ul class="data_text">
            <li><u>High-level</u>: look at key results in short summaries -
                get an idea of what's going on in the field.</li>
            <li><u>A bit deeper</u>: for topics which interest you more,
                read longer summaries with illustrations and explanations.
                Take a walk through the authors' reasoning steps and key observations. </li>
            <li><u>In depth</u>: read the papers you liked. Now, when you got the main idea, this
            is going to be easier!</li>
            </ul>
</fieldset>

        <br><br>



        <p class="data_text" style="font-size:24px;color:#7a3160">What's inside:</p>
        <ul class="data_text" style="font-size:20px;color:#7a3160">
            <li><a href="#papers_common_practice">Common Practice</a></li>
            <li><a href="#papers_architectures">Model Architectures</a></li>
            <li><a href="#papers_analysis">A Bit of Analysis</a></li>
            <li><a href="#papers_reading_behavior">Language Models and Human Reading Behavior</a></li>
            <li><a href="#papers_smoothings">N-gram LMs: More Smoothings</a></li>
            <li>... to be updated</li>
        </ul>


        <br><br>

        <!--##################################################-->
        <!--##################################################-->
        <!--##################################################-->

        <div class="paper_circle" style="float:left;"></div>
        <h2 style="margin-top:-10px; float: left; padding-left:10px; padding-right:10px; color:#7a3160">
            Common Practice</h2>
        <div class="box_pink_left" id="papers_common_practice">


        <!--##################################################-->
        <div class="paperCard" id="thumbnail_paper" >
            <div class="paperIntro" id="paper_weight_tying">

              <div class="cardContent">

                  <div class="paper_title">
                      <a href="https://arxiv.org/pdf/1611.01462.pdf" target="_blank" class="links">
                      Tying Word Vectors and Word Classifiers: a Loss Framework for Language Modeling
                      </a>
                  </div>

                <div class="paper_authors">
                    Hakan Inan, Khashayar Khosravi, Richard Socher
                </div>
                <hr color="#f2e4ee" style="margin:5px;">
                  <p>One of the papers discussing weight tying trick in neural LMs:
                    use the same parameters for input and output word embedding layers.
                    Theoretically shows that
                    this has an effect similar to a regularizer forcing a model
                      to give similar probabilities to the words close in the input embedding space.
                  </p>

              </div>

                <div>
                    <div class="conf_name">ICLR 2017</div>
                  <a href="https://arxiv.org/pdf/1611.01462.pdf" target="_blank">
                      <img width=100% src="../resources/lectures/lang_models/papers/weight_tying-min.png"
                           alt="" style="margin-top:20px;" class="center"/>
                  </a>
                </div>

             </div>
            <hr color="#f2e4ee" style="margin:5px">
            <div class="cardContent">
                <details>
                    <summary style="margin-left:10px;">More details</summary>

                    <h2>Loss Idea: High Probability for the Words Similar to Target</h2>
                    <img width=90% src="../resources/lectures/lang_models/papers/similarity_loss_idea-min.png"
                           alt="" style="margin-top:20px;margin-bottom:20px;" class="center"/>
                    <p>The standard loss function is cross-entropy with one-hot targets.
                        This means that in the example above we will ask the model to assign probability 1 to
                        the token <span class="data_text"><strong>cat</strong></span> and zero for the rest.
                        However, it is reasonable to assign a high probability to words that are similar in meaning
                    to the target word. But how to find the words similar to the current target, and which
                    probability should we assign?</p>
                    <img width=40% src="../resources/lectures/lang_models/papers/weight_tying_emb_sim-min.png"
                               alt="" style="margin-left:20px; float:right;" class="center"/>
                    <p>To evaluate similarity between the target word
                        (i.e., <span class="data_text"><strong>cat</strong></span>)
                        and other words in the vocabulary, we can use input word embeddings.
                        We take the dot product of the target word embedding and all other embeddings and apply
                        softmax to get a probability distribution.
                    </p>

                    <p>Now we can add a new term to the loss function which would encourage
                        a model to assign high probability to the words similar to the target.
                    </p>
                    <img width=80% src="../resources/lectures/lang_models/papers/weight_tying_total_loss-min.png"
                               alt="" style="margin-bottom:20px;" class="center"/>


                    <h2>The Effect: Similar to Weight Tying</h2>
                    <p>The authors show theoretically that the effect of optimizing the
                    new training objective (with the regularizer) is similar to using the
                        same parameters for input and output words embeddings ("weight tying").</p>

                    <h2>Benefits of Weight Tying</h2>
                    <ul>
                        <li><font face="arial">quality and convergence speed</font><br>
                            Experiments show that models with shared embeddings can have better quality and
                            converge faster. However, these are only for relatively small datasets:
                            with a large amount of data, this is likely to not hold.
                        </li>
                        <li><font face="arial">smaller model</font><br>
                            Since the embeddings layers have a lot of parameters (emb. size * |V|),
                            weight tying significantly reduces model size (e.g., by 25-30%;
                            of course, this depends on model and vocabulary size).
                        </li>
                    </ul>

                </details>
            </div>
        </div>

        <!--##################################################-->


        <!--##################################################-->
        <!--
            <div class="paperCard" id="thumbnail_paper" >
            <div class="paperIntro">

              <div class="cardContent">

                  <div class="paper_title">
                      <a href="" target="_blank" class="links">
                      ???
                      </a>

                  </div>

                <div class="paper_authors">
                    ???, ???, ???
                </div>
                <hr color="#f2e4ee" style="margin:5px;">


              </div>

                <div>
                    <div class="conf_name">???</div>
                  <a href="" target="_blank">
                      <img src="../resources/lectures/word_emb/papers/???-min.png"
                           alt="" style="margin-top:20px;" class="center"/>
                  </a>
                </div>

             </div>
            <hr color="#f2e4ee" style="margin:5px">
            <div class="cardContent">
                <details>
                    <summary style="margin-left:10px;">More details</summary>
                    <br>

                    Lorem ipsum dolor sit, amet consectetur adipisicing elit. A sed nobis ut exercitationem atque accusamus sit natus officiis totam blanditiis at eum nemo, nulla et quae eius culpa eveniet voluptatibus repellat illum tenetur, facilis porro. Quae fuga odio perferendis itaque alias sint, beatae non maiores magnam ad, veniam tenetur atque ea exercitationem earum eveniet totam ipsam magni tempora aliquid ullam possimus? Tempora nobis facere porro, praesentium magnam provident accusamus temporibus! Repellendus harum veritatis itaque molestias repudiandae ea corporis maiores non obcaecati libero, unde ipsum consequuntur aut consectetur culpa magni omnis vero odio suscipit vitae dolor quod dignissimos perferendis eos? Consequuntur!
                </details>
            </div>
        </div>
-->

        <!--##################################################-->

        </div>
        <div class="paper_circle" style="float:left;"></div>

        <!--##################################################-->
        <!--##################################################-->
        <!--##################################################-->


            <br><br>
        <!--##################################################-->
        <!--##################################################-->
        <!--##################################################-->

        <div class="paper_circle" style="float:left;"></div>
        <h2 style="margin-top:-10px; float: left; padding-left:10px; padding-right:10px; color:#7a3160">
            Model Architectures</h2>
        <div class="box_pink_left" id="papers_architectures">

        <!--##################################################-->
        <div class="paperCard" id="thumbnail_paper" >
            <div class="paperIntro">

              <div class="cardContent">

                  <div class="paper_title">
                      <a href="https://arxiv.org/pdf/1612.08083.pdf" target="_blank" class="links">
                      Language Modeling with Gated Convolutional Networks
                      </a>
                  </div>

                <div class="paper_authors">
                    Yann N. Dauphin, Angela Fan, Michael Auli, David Grangier
                </div>
                <hr color="#f2e4ee" style="margin:5px;">
                  In contrast to the common belief, the authors show that
                  infinite context is not necessary for good LMs.
                  They propose a model with stacked convolutions and
                  a new gating mechanism, <font face="arial">Gated Linear Unit (GLU).</font>
                  Because convolutions are easy to parallelize over the words,
                  this model is much faster to train than LSTMs.

              </div>

                <div>
                    <div class="conf_name">ICML, 2017</div>
                  <a href="https://arxiv.org/pdf/1612.08083.pdf" target="_blank">
                      <img src="../resources/lectures/lang_models/papers/glu_paper-min.png"
                           alt="" style="margin-top:20px;" class="center"/>
                  </a>
                </div>

             </div>
            <hr color="#f2e4ee" style="margin:5px">
            <div class="cardContent">
                <details>
                    <summary style="margin-left:10px;">More details</summary>
                    <br>
                    <h2>Gated Linear Unit</h2>
                    <p>Instead of simple convolutions, the paper introduced <font face="arial">Gated Linear Units</font>
                    which became quite popular. The idea is similar to LSTM, but not from left to right, but from
                        bottom to top.</p>
                        <img src="../resources/lectures/lang_models/papers/glu_paper-min.png"
                           alt="" width=40% style="margin-left:20px;float:right;"/>
                    <p> In addition to extracting features and passing them to the next layer,
                        we also learn which features we want to pass for this token and which ones we don't.
                        For this, a convolution extracts \(2d\) features:</p>
                    <ul>
                        <li>\(d\) <font face="arial">content features</font><br>
                            These are the main features - they extract information from input.
                        </li>
                        <li>\(d\) <font face="arial">gate features</font><br>
                        The gate features are used to mask out content features.
                        They are passed to the sigmoid function - it transforms the features into
                        "gate values" from 0 to 1.
                        </li>
                    </ul>

                        <img src="../resources/lectures/lang_models/papers/glu_model-min.png"
                           alt="" width=50% style="margin-left:20px;float:right;"/>
                    <h2>Model Architecture</h2>
                    <p>The model architecture is shown in the figure.
                        It consists of several blocks with a GLU layer (or several of them)
                        wrapped in a residual block. The paper tries different models:
                        with convolutional kernels 1-6 and different numbers of layers and filters.
                    </p>




                    <h2>Quality and Context Size</h2>
                    <p>The figure below shows model quality depending on context size (context size
                        is the CNN receptive field; it is evaluated as we saw
                        <a href="#receptive_field">here</a>). All in all, if you stack
                        the number of layers sufficient to cover about 40 tokens, your model
                        will be quite good.
                    </p>
                    <img src="../resources/lectures/lang_models/papers/glu_context_size-min.png"
                           alt="" width=100% style="margin-top:20px;margin-bottom:20px;float:right;"/>
                    <p>Note that while both ngram and convolutional models have fixed context size,
                        this causes problems only for ngram models: they can not have a large context.
                        In contrast, with several convolutional layers you can process long contexts.
                    </p>

                    <h2>More in the paper</h2>
                    <ul>

                        <li>the model outperforms the comparable LSTM;</li>
                        <li>the model is much faster to train than LSTMs.
                        </li>
                    </ul>

                    More details in
                    <a href="https://arxiv.org/pdf/1612.08083.pdf" target="_blank">the original paper</a>!

                </details>
            </div>
        </div>

        <!--##################################################-->


        </div>
        <div class="paper_circle" style="float:left;"></div>

        <!--##################################################-->
        <!--##################################################-->
        <!--##################################################-->

    <br><br>

        <!--##################################################-->
        <!--##################################################-->
        <!--##################################################-->

        <div class="paper_circle" style="float:left;"></div>
        <h2 style="margin-top:-10px; float: left; padding-left:10px; padding-right:10px; color:#7a3160">
            A Bit of Analysis</h2>
        <div class="box_pink_left" id="papers_analysis">

        <!--##################################################-->
        <div class="paperCard" id="thumbnail_paper" >
            <div class="paperIntro">

              <div class="cardContent">

                  <div class="paper_title">
                      <a href="https://www.aclweb.org/anthology/N18-1108.pdf" target="_blank" class="links">
                      Colorless green recurrent networks dream hierarchically
                      </a>
                  </div>

                <div class="paper_authors">
                    Kristina Gulordava, Piotr Bojanowski, Edouard Grave, Tal Linzen, Marco Baroni
                </div>
                <hr color="#f2e4ee" style="margin:5px;">
                  <a href="#analysis_contrastive">As we saw earlier</a>,
                  contrastive evaluation can be used to check whether a model is grammatical
                  by testing e.g. subject-verb agreement. But how do we know
                  if it learned syntax or just collocations/semantic? The authors suggest a really
                  fun way to find out: let's take sentences that do not make sense
                  and look if a model generates the correct inflection.

              </div>

                <div>
                    <div class="conf_name">NAACL, 2018</div>
                  <a href="https://www.aclweb.org/anthology/N18-1108.pdf" target="_blank">
                      <img src="../resources/lectures/lang_models/papers/gulordava_paper-min.png"
                           alt="" style="margin-top:20px;" class="center"/>
                  </a>
                </div>

             </div>
            <hr color="#f2e4ee" style="margin:5px">
            <div class="cardContent">
                <details>
                    <summary style="margin-left:10px;">More details</summary>
                    <br>
                    <h2>How nonsense can help your research</h2>
                    <p>To distinguish between cases where a model indeed learned grammatical
                        agreement or just collocation, the authors test not only "normal" examples,
                        but also the ones which do not make sense. E.g. does a model predict the correct agreement
                        in the sentence
                        <font class="data_text"><strong>
                            The colorless green <font color="#79a123">ideas</font> I ate with the chair
                            <font color="#79a123">sleep</font> furiously
                        </strong></font>?
                    </p>
                    <p>The authors generate such examples: they take an original sentence and
                        replace some words with random words, but preserving part-of-speech and morphological inflection.
                        One example was shown above.
                    </p>

                    <p>Look at the results ("5-gram KN" is the 5-gram model with
                        <a href="#papers_smoothings">Kneser-Ney smoothing</a>).
                    </p>

                    <img src="../resources/lectures/lang_models/papers/gulordava_results-min.png"
                           alt="" width=100% style="margin-top:20px;margin-bottom:20px;float:right;"/>

                    <p>The results show that:</p>
                    <ul>
                        <li><font face="arial">for n-gram models, context does not help</font><br>
                            For nonce sentences, 5-gram models are not better than unigram. A bit better
                            for normal sentences though.
                        </li>
                        <li><font face="arial">with the same context, LSTMs are a lot better than n-gram</font><br>
                            The difference is huge for both original and nonce examples.
                            This is the power
                            of neural networks - they "know" which words are similar, while n-gram
                            models rely only on co-occurrence.<br>
                            <font face="arial">Size is not the only thing that matters!</font>
                            Neural models are better not only because of
                            <font face="arial">context size</font> but also because of
                            <font face="arial">how</font> they process this context.
                        </li>
                        <li><font face="arial">for LSTMs, large context does help</font><br>
                            This is nice - it means that LSTMs do use long contexts. Note also that the scores
                            are quite high
                            even for nonce sentences!
                        </li>
                    </ul>

                    <h2>More in the paper</h2>
                    <ul>

                        <li>the detailed procedure for generating nonce examples;</li>
                        <li>results and discussion for specific grammatical constructions.
                        </li>
                    </ul>

                    More details in
                    <a href="https://www.aclweb.org/anthology/N18-1108.pdf" target="_blank">the original paper</a>!


                </details>
            </div>
        </div>

        <!--##################################################-->


        </div>
        <div class="paper_circle" style="float:left;"></div>

        <!--##################################################-->
        <!--##################################################-->
        <!--##################################################-->


        <br><br>
        <!--##################################################-->
        <!--##################################################-->
        <!--##################################################-->

        <div class="paper_circle" style="float:left;"></div>
        <h2 style="margin-top:-10px; float: left; padding-left:10px; padding-right:10px; color:#7a3160">
            Language Models and Human Reading Behavior</h2>
        <div class="box_pink_left" id="papers_reading_behavior">
<br><br>
        <p class="data_text" style="margin-top:-20px"><font color="#888">
            <u>Lena</u>: This is not what you will typically see at the "Related Papers"
            lists for a language modeling lecture (at least, I never saw in any).
            But when I first found this, I was so excited, that I can't help sharing it with you :)
        </font></p>

            <!--##################################################-->
        <div class="paperCard" id="thumbnail_paper" >
            <div class="paperIntro">

              <div class="cardContent">

                  <div class="paper_title">
                      <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3709001/pdf/nihms-455892.pdf" target="_blank" class="links">
                      The effect of word predictability on reading time is logarithmic
                      </a>
                  </div>

                <div class="paper_authors">
                    Nathaniel J. Smith and Roger Levy
                </div>
                <hr color="#f2e4ee" style="margin:5px;">
                  The time it takes humans to read a word can be predicted from estimates of the word's
                  probability in context. The paper shows that
                  (i) P(word|context) from an n-gram language model is a very good predictor of this time;
                  (ii) the relationship between word log-probability and reading time is (near-)linear
                  (see the figure).

              </div>

                <div>
                    <div class="conf_name">Cognition, 2013</div>
                  <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3709001/pdf/nihms-455892.pdf" target="_blank">
                      <img src="../resources/lectures/lang_models/papers/reading_slowdown-min.png"
                           alt="" style="margin-top:20px;" class="center"/>
                  </a>
                </div>

             </div>
            <hr color="#f2e4ee" style="margin:5px">
            <div class="cardContent">
                <details>
                    <summary style="margin-left:10px;">More details</summary>

                    <h2>Time to read vs Predictability of a word in the context</h2>

                    <p>When we read a text, the time taken to read each word is related to our expectations
                        about this word: the more "expected" a word is, the less time we need to read it.
                        However, the exact functional relation between this per-word processing time in humans
                        and the "predictability" of a word given context was not known.
                    </p>

                    <p>The key point of this paper is that a language model can be used to estimate
                        the "predictability" of a word given context.
                    </p>

                    <h2>Computational LM instead of a Human one - a very novel idea</h2>

                    <p>Previously, the predictability of a word given context was estimated
                    in cloze-style tasks: humans were asked to guess the next word given context.
                        For example, to continue the sentences
                    </p>

                    <p class="data_text" style="margin-left: 30px;">
                        (1) My brother came inside to...<br>
                        (2) The children went outside to...
                    </p>
                    <p>In the first case, the continuation can be very different, but in the second case,
                        about 90% of participants suggest the word <font class="data_text"><strong>play</strong></font>.</p>

                    <p>While this data estimates the word predictability directly, it is very sparse:
                    for most of the continuations, there's no data at all.
                        That's why the idea to use a <font face="arial">computational</font>
                        language model instead of a human one was so groundbreaking:
                        <font face="arial">it allowed to estimate word predictability very easily</font>.
                    </p>


                    <h2>Components of the study</h2>
                    <p><font face="arial">Data with human behavior:</font></p>
                    <ul>
                        <li><font face="arial">eye-tracking</font><br>
                            Eye movements of native speakers reading a newspaper text.
                        </li>
                        <li><font face="arial">self-paced reading</font><br>
                            Moving-window self-paced reading times:
                            the participant must press a button to reveal each word in turn. Data recorded:
                             the times between button presses.
                        </li>
                    </ul>

                    <p><font face="arial">Language model:</font> 3-gram with Kneser-Ney smoothing.</p>



                    <img src="../resources/lectures/lang_models/papers/reading_slowdown2-min.png"
                           alt="" width=30% style="margin-top:20px;margin-left:20px;float:right;"/>
                    <h2>Results</h2>
                    <ul>
                        <li>computational language models can be very good at predicting
                        time taken by humans to read a word;</li>
                        <li>the functional relationship between reading time and predictability is
                            now known: it is
                            logarithmic (i.e.,
                            the relationship between word log-probability and reading time is (near-)linear - this
                            is what we see on the figure).</li>
                    </ul>

                    Of course,
                    <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3709001/pdf/nihms-455892.pdf" target="_blank">
                        the original paper</a>
                    has much more details!


                </details>
            </div>
        </div>

        <!--##################################################-->


        <!--##################################################-->
        <div class="paperCard" id="thumbnail_paper" >
            <div class="paperIntro">

              <div class="cardContent">

                  <div class="paper_title">
                      <a href="https://arxiv.org/pdf/2006.01912.pdf" target="_blank" class="links">
                      On the Predictive Power of Neural Language Models for Human Real-Time Comprehension Behavior
                      </a>

                  </div>

                <div class="paper_authors">
                    Ethan G. Wilcox, Jon Gauthier, Jennifer Hu, Peng Qian, Roger P. Levy
                </div>
                <hr color="#f2e4ee" style="margin:5px;">
                  In light of the previous work, explore which LMs
                  (across architectures and datasets)
                  are better at predicting
                  human behavior.
                  Overall, the traditional LM perplexity is a good estimate of this.
                  Strangely, Transformers (which we'll meet at the next
                  lecture) and n-gram LMs are better than LSTMs.
              </div>

                <div>
                    <div class="conf_name">2020</div>
                  <a href="https://arxiv.org/pdf/2006.01912.pdf" target="_blank">
                      <img src="../resources/lectures/lang_models/papers/reading_slowdown_across_models-min.png"
                           width=90% alt="" style="margin-top:20px;" class="center"/>
                  </a>
                </div>

             </div>
            <hr color="#f2e4ee" style="margin:5px">
            <div class="cardContent">
                <details>
                    <summary style="margin-left:10px;">More details</summary>
                    <h3>Considered models</h3>
                    <ul>
                        <li><font face="arial">5-gram</font>: 5-gram LM with Kneser-Ney smoothing;</li>
                        <li><font face="arial">LSTM</font>: the standard ones;</li>
                        <li><font face="arial">RNNG</font>: models the joint probability of a sequence of words as well
                            as its syntactic structure;</li>
                        <li><font face="arial">GPT-2</font>: Transformer LM. This a very popular model which we'll
                            meet a bit later in the course.</li>
                    </ul>

                    <h2>LM Surprisal vs Reading Times</h2>
                    <img src="../resources/lectures/lang_models/papers/reading_slowdown_across_models2-min.png"
                           width=50% alt="" style="margin-left:20px; float: right;"/>
                    <p>The figure shows the relationship between LM "surprisals" (negative log-probability)
                        and human reading times
                        for all models and corpora (more in the original paper!). Main observations are:</p>
                    <ul>
                        <li>the relationship is <font face="arial">linear</font> for all models;</li>
                        <li>human reading time has higher variance with respect to LSTM predictions
                            than with respect to predictions of other models.
                        </li>
                    </ul>

                    <h2>Psychometric Predictive Power vs LM Perplexity</h2>
                    <img src="../resources/lectures/lang_models/papers/perplexity_vs_predictive_power-min.png"
                           width=50% alt="" style="margin-left:20px; float: right;"/>

                    <p>(The scary phrase <font face="arial">"psychometric predictive power"</font> simply
                        means how good is an LM at predicting human behavior.)</p>

                    <p>Generally, we see that models with lower perplexity
                        (in NLP, we think are good models) are also good at predicting human behavior.</p>



                </details>
            </div>
        </div>

        <!--##################################################-->

        </div>
        <div class="paper_circle" style="float:left;"></div>

        <!--##################################################-->
        <!--##################################################-->
        <!--##################################################-->









        <br><br>

        <!--##################################################-->
        <!--##################################################-->
        <!--##################################################-->

        <div class="paper_circle" style="float:left;"></div>
        <h2 style="margin-top:-10px; float: left; padding-left:10px; padding-right:10px; color:#7a3160">
            N-gram LMs: More Smoothings</h2>
        <div class="box_pink_left" id="papers_smoothings">
<br><br>
        <!--
        <p class="data_text" style="margin-top:-20px"><font color="#888">
            <u>Lena</u>: to be honest, I doubt you will need this -
        n-gram language models are not widely used. A quick look at other ML for NLP courses
            showed that this part is omitted in most of them.
        I hope, however, that some of you may be interested in this.
            All in all, this is part of our history I'm not yet ready to throw away :)</font></p>
        -->


        <!--##################################################-->
        <!--
            <div class="paperCard" id="thumbnail_paper" >
            <div class="paperIntro">

              <div class="cardContent">

                  <div class="paper_title">
                      <a href="" target="_blank" class="links">
                      Goog-Turing Smoothing
                      </a>
                  </div>

                <div class="paper_authors">
                    ???, ???
                </div>
                <hr color="#f2e4ee" style="margin:5px;">

              </div>

                <div>
                    <div class="conf_name">???</div>
                  <a href="" target="_blank">
                      <img src="../resources/lectures/word_emb/papers/???-min.png"
                           alt="" style="margin-top:20px;" class="center"/>
                  </a>
                </div>

             </div>
            <hr color="#f2e4ee" style="margin:5px">
            <div class="cardContent">
                <details>
                    <summary style="margin-left:10px;">More details</summary>



                </details>
            </div>
        </div>
          -->

        <!--##################################################-->


        <!--##################################################-->
            <h3 style="color:#7a3160"> Kneser-Ney Smoothing</h3>
        <div class="paperCard" id="thumbnail_paper" >
            <div class="paperIntro">

              <div class="cardContent">

                  <div class="paper_title">
                      <a href="http://www-i6.informatik.rwth-aachen.de/publications/download/951/Kneser-ICASSP-1995.pdf" target="_blank" class="links">
                      Improved backing-off for M-gram language modeling
                      </a>

                  </div>

                <div class="paper_authors">
                    Reinhard Kneser, Hermann Ney
                </div>
                <hr color="#f2e4ee" style="margin:5px;">
                  <p>Simple back-off smoothings discard context and back off from n-grams to k-grams with k < n.
                      But let's take for example a phrase
                      <font class="data_text"><strong>San Francisco</strong></font>:
                      it is common and <font class="data_text"><strong>Francisco</strong></font>
                      will have a high unigram probability. And here's the problem:
                      <font class="data_text"><strong>Francisco</strong></font> appears mostly after
                      <font class="data_text"><strong>San</strong></font>, but when backing off,
                      it's large unigram probability will result in a large probability of
                      <font class="data_text"><strong>Francisco</strong></font> after <font face="arial">any</font>  token!
                  </p>


              </div>

                <div>
                    <div class="conf_name">ICASSP 1995</div>
                  <a href="http://www-i6.informatik.rwth-aachen.de/publications/download/951/Kneser-ICASSP-1995.pdf" target="_blank">
                      <img width=80% src="../resources/lectures/lang_models/papers/san_francisco-min.png"
                           alt="" style="margin-top:20px;" class="center"/>
                  </a>
                </div>

             </div>
            <hr color="#f2e4ee" style="margin:5px">
            <div class="cardContent">
                <details>
                    <summary style="margin-left:10px;">More details</summary>
                    <br>

                    <h2>Unigram Probability: Stupid Back-off vs Kneser-Ney</h2>
                    <p>Before looking at the full Kneser-Ney formula, let's first
                    compare the unigram probabilities for a token which uses Kneser-Ney
                        and stupid back-off smoothings. Stupid Back-off is based on
                        simple unigram counts \(N(w_i)\): the number of times \(w_i\)
                        occurs in the corpus. As we mentioned earlier, this won't
                        work well for examples like <font class="data_text"><strong>San
                        Francisco</strong></font>.
                    </p>

                        <center>
                        <img width=80% src="../resources/lectures/lang_models/papers/stupid_vs_kneser-min.png"
                           alt="" style="margin:20px;"/>
                        </center>

                        <p>In contrast to simple back-off, Kneser-Ney smoothing
                        uses not the raw counts, but the number of tokens \(w_i\) can follow.
                        Intuitively, this is exactly what we want: we need
                        something which tells us how likely \(w_i\) can continue a prefix.
                        In our example,
                        <font class="data_text"><strong>
                        Francisco</strong></font> will get low probability (just as it should).
                    </p>

                    <h2>Going Further: Iterative Formula</h2>
                    <p>For the full formula, we need to define one more count:</p>
                    <center>
                    <img width=100% src="../resources/lectures/lang_models/papers/kn_words_follow-min.png"
                       alt="" style="margin-bottom:20px;"/>
                    </center>

                    <p>The full back-off formula for Kneser-Ney is shown below. </p>
            <img width=100% src="../resources/lectures/lang_models/papers/kneser_ney_formula2-min.png"
                           alt="" style="margin-top:20px;"/>
                </details>
            </div>
        </div>

        <!--##################################################-->

        </div>
        <div class="paper_circle" style="float:left;"></div>

        <!--##################################################-->
        <!--##################################################-->
        <!--##################################################-->


    <br><br>
    <div style="border: 0px solid #ccc;border-radius:15px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;margin-top:-20px;">
    <div style="display: grid; grid-template-columns: 75% 25%; margin:10px;">
                <div>
                <div style="margin-top:20px;">
                    <p style="margin:30px; font-size:30px;">Here will be more papers!</p>

                    <p style="margin:30px;">The papers will be gradually appearing.</p>
                </div>
                    </div>
                <div>
                    <center>
                    <img src="../../resources/lectures/main/preview/pusheen_reads_on_white-min.png"
                       style="width:80%; padding-top:20px; padding-bottom:20px;border-radius:50%">
                    </center>
                </div>
            </div>

        </div>
    </div>

</div>


<br><br><br>
<div id="have_fun">
<img height="40" src="../resources/lectures/ico/fun_empty.png"
     style="float:left; padding-right:10px; margin-top:-20px;"/>
<h1 style="margin-left:10px; margin-right:20px; float: left; margin-top:-20px">Have Fun!</h1>
<hr color="#c8edfa" style="height:5px">
<br><br>

<!--
    <div style="border: 0px solid #ccc;border-radius:15px;margin: 10px; padding: 4px;
 background-color: #f5f5f5;margin-top:-20px;">
    <div style="display: grid; grid-template-columns: 75% 25%; margin:10px;">
                <div>
                <div style="margin-top:20px;">
                    <p style="margin:30px; font-size:30px;">Coming soon!</p>

                    <p style="margin:30px;">We are still working on this!</p>
                </div>
                    </div>
                <div>
                    <center>
                    <img src="../../resources/lectures/main/preview/typing.gif"
                       style="width:80%; padding-top:20px; padding-bottom:20px;border-radius:50%">
                    </center>
                </div>
            </div>
    </div>
-->


<fieldset style="border: 1px solid #008cbf;
    border-radius: 5px;font-size:18px;">
            <legend><p class="data_text" style="font-size:24px;">
                <font color="#008cbf"><strong>Paper writer</strong></font></p></legend>
            <p class="data_text">
            We learned all about language models, now let's see how it works! We give you a model that
                for each prefix can propose some suggestions. You can choose the continuation you want
                by clicking on the figure and you can do it many times. Your task is to write a paper!
    </p>

    <p></p>

    <p class="data_text" style="font-size:14px;">
        <font color="#888">Big thanks
        <a href="https://github.com/justheuristic">Just Heuristic</a> for the help with technical issues! Just Heuristic - Just Fun!
        </font> </p>
</fieldset>

        <br><br>



    <center>
    <div class="lm_window" id="lm_window" style="width: 100%;">
        <div class="cardContent">
            <p class="prompt_text">Let's write a paper!</p>
            <p class="comment_text" style="font-size:18px;">
                    Every great paper starts with an inciting thought - something only a human can have ...<br>
                </p>
            <hr color="#e9f0f2" style="margin:5px; display: block">
            <div id="lm_prompt_screen" style="display: block">
                <div class="prompt_and_button" style="margin-top: 0px;">
                    <div style="width: 85%; margin-left: 7%;">
                        <p class="data_text" style="font-size: 16px; color: gray; text-align:left; margin-bottom: -2px;">
                            Write a prefix, for example: "Deep Variational" (without quotes)</p>
                        <textarea class="input_prompt"
                                  style="width: 100%; max-width: 100%; min-height: 72px;
                                         resize: vertical; font-size:14px;"></textarea>
                    </div>
                    <div class="next" style="opacity:0.2; transform: translate(-32px, 35px);">
                        <div class="next_button"></div>
                        <p class="next_text">Start!</p>
                    </div>
                </div>

                <p class="comment_text status_comment" id="aftertext_jk" style="color:gray; font-size: 16px">
                    Waiting for the model to load... (this should take 3-5s)
                </p>
            </div>


            <div id="lm_generate_screen" style="display: none">
                <div style="width: 85%; margin-left: 7%; float: center; display: block">
                    <p class="data_text"
                       style="font-size: 16px; color: gray; text-align:left; margin-bottom: -2px; margin-left: 5px;">
                        Currently generated text ("@@" is a BPE split). Click on the circles below to add tokens.</p>
                    <textarea class="input_preprocessed"
                              style="width: 100%; resize: vertical; margin-left: 5px; font-size:14px;" disabled=true></textarea>
                </div>
                <div id="d3_container" style="width: 85%; display:block; margin: 0 auto;">
                    <svg id="d3_beamsearch_svg" width=100% height=240px></svg>
                </div>
                <button class="rect_button button_add_greedy"
                        onclick="console.warn('generate button should not be available at this point')">
                    <p class="button_text" style="font-size:16px">Add greedy</p>
                </button>
                <button class="rect_button button_backspace"
                        onclick="console.warn('backspace button should not be available at this point')">
                    <p class="button_text" style="font-size:16px">Backspace</p>
                </button>
                <button class="rect_button button_restart"
                        onclick="console.warn('restart button should not be available at this point')">
                    <p class="button_text" style="font-size:16px">Restart</p>
                </button>
            </div>
        </div>
    </div>
    </center>

    <script> // this script ONLY defines global constants
        var beam_size = 4;
        var search_length = 5;
    </script>

    <script> // this <script> defines model, vocabularies & auxiliary functions, NOT the interface
        var model, lstm_units, emb_size, voc_size, bpe_rules, vocab, bos, eos, unk,
            token_to_ix={}, bpe_rule_priority={}, is_initialized=false;  // to be initialized
        let tokenizer_regex = new RegExp(/([A-zÀ-ÿ-]+|[0-9._]+|.|!|\?|'|"|:|;|,|-)/i);
        let bpe_terminal = "</w>", bpe_sep = "@@";

        async function async_initialize_model() {
            console.assert(!is_initialized, "Model was initialized more than once!")
            model = await tf.loadLayersModel('../resources/lectures/lang_models/fun/lm/model.json');
            voc_response = await fetch('../resources/lectures/lang_models/fun/voc.json');
            [lstm_units, emb_size, voc_size, bpe_rules, vocab, bos, eos, unk] = await voc_response.json();
            vocab.forEach((token, index) => token_to_ix[token] = index);
            bpe_rules.forEach((pair, index) => bpe_rule_priority[pair[0] + " " + pair[1]] = index);
            is_initialized = true;
        }

        function preprocess(string) {
            // raw string -> array of tokens -> array of bpe segments
            console.assert(is_initialized, "Model is not initialized!")
            return tokenize(string).flatMap(bpeize_token)
        }

        function tokenize(string) {
            let tokens = [];
            string.split(tokenizer_regex)
                .filter(token => (token != ' ' && token != '' && token != '\n'))
                .forEach(token => tokens.push(token.toLowerCase()))
            return tokens
        }

        function bpeize_token(token) {
            // split a single token into an Array of bpe segments; equivalent to https://github.com/rsennrich/subword-nmt v0.2
            let segments = token.split('');
            segments[segments.length - 1] += bpe_terminal;

            while(segments.length > 1){
                // find bpe rule with lowest index
                var best_rule_index = Infinity;
                for(let i = 0; i < segments.length - 1; i++) {
                    let cand = segments[i] + " " + segments[i + 1];
                    if ((cand in bpe_rule_priority) && (bpe_rule_priority[cand] < best_rule_index))
                        best_rule_index = bpe_rule_priority[cand];
                }
                if (best_rule_index == Infinity)
                    break
                // apply that rule everywhere
                let [chosen_left, chosen_right] = bpe_rules[best_rule_index];
                for(let i = segments.length - 2; i >= 0; i--) {
                    if (segments[i] == chosen_left && segments[i + 1] == chosen_right) {
                        segments.splice(i + 1, 1);
                        segments[i] = chosen_left + chosen_right;
                    }
                }

            }
            // don't print </w> symbols
            end = segments.length - 1
            if (segments[end] == bpe_terminal)
                segments.pop()
            else if (segments[end].endsWith(bpe_terminal))
                segments[end] = segments[end].slice(0, segments[end].length - bpe_terminal.length);

            // append bpe separator to all segments except last
            for (let i = 0; i < segments.length - 1; i++)
                segments[i] += bpe_sep;

            return segments
        }

        function get_initial_state() {
            console.assert(is_initialized, "Model is not initialized!")
            return [tf.zeros([1, voc_size]), tf.zeros([1, lstm_units]), tf.zeros([1, lstm_units])]
        }

        function generate_beam_search_vertices(prev_state) {
            // runs beam search with up to beam_size hypotheses for search_length steps
            // updates bokeh data source (and hence, the data shown in bokeh
            var [prev_logits, prev_hid, prev_cell] = prev_state;
            var plot_data = [
                { x: 0.0, y: 0.0, token_text: "<...>", circle_text: "#1",
                 edge: [{x: -0.5, y: 0.0}, {x: 0, y: 0}], parent_index: -1},
            ]
            var parent_i = 0;
            for (let t = 0; t < search_length; t++) {

                var token_ix = prev_logits.argMax(-1);

                var best_token_indices = findIndicesOfMax(prev_logits.arraySync()[0], beam_size)
                for (let i = 0; i < best_token_indices.length; i++){
                    var token = vocab[best_token_indices[i]];
                    plot_data.push({
                        x: t + 1, y: 1.5 * i, token_text: token, circle_text: `#${i + 1}`,
                        edge: [{x: plot_data[parent_i].x, y: plot_data[parent_i].y},
                               {x: t + 1, y: 1.5 * i}], // add edge from parent to oneself
                        parent_index: parent_i,
                    })
                }

                [prev_logits, prev_hid, prev_cell] = model.predict([token_ix.reshape([1, -1]), prev_hid, prev_cell]);
                parent_i = plot_data.length - beam_size;
            }
            return plot_data;
        }

        function sleep(ms) {return new Promise(resolve => setTimeout(resolve, ms));}
        function findIndicesOfMax(inp, count) {
            var outp = [];
            for (var i = 0; i < inp.length; i++) {
                outp.push(i); // add index to output array
                if (outp.length > count) {
                    outp.sort(function(a, b) { return inp[b] - inp[a]; }); // descending sort the output array
                    outp.pop(); // remove the last index (index of smallest element in output array)
                }
            }
            return outp;
        }

    </script>

    <script> // this script ONLY draws d3js charts and nothing else
        var svg = d3.select("#d3_beamsearch_svg");
        var d3_div = document.getElementById('d3_container');
        var x_scale, y_scale, circle_containers, beam_search_ready = false;
        var example_plot_data = [ { x: 0.0, y: 0.0, token_text: "<...>", circle_text: "#1",
                                  edge: [{x: -0.5, y: 0.5}, {x:0, y:0}], parent_index: -1},
        ]; // this is an example, the actual data will be filled in by generate_beam_search_vertices
        var circle_attrs = {r: 12, fill: "#87CEEB", stroke: "navy", "stroke-width": 1.5};
        var line_attrs = {
            fill: "none", stroke: "black", "stroke-width": 1.0,
            d: (function(plot_data_elem)
                      {return d3.svg.line()
                          .x(function(d_i) { return x_scale(d_i.x); })
                          .y(function(d_i) { return y_scale(d_i.y); })
                          (plot_data_elem.edge)})
        };

        // TODO features: change line width if is_best, change in some other way if selected

        function draw_beam_search_vertices(plot_data, callback_on_click) {
            svg.selectAll("*").remove();
            x_scale = d3.scale.linear().domain([-0.25, search_length + 0.35]).range([0, d3_div.clientWidth]);
            y_scale = d3.scale.linear().domain([-1.0, 1.5 * (beam_size - 1) + 0.5]).range([0, d3_div.clientHeight]);

            svg.selectAll(".line").data(plot_data).enter().append("path").attr(line_attrs);

            circle_containers = svg.selectAll("g circleWithText").data(plot_data).enter().append("g")
                .attr("transform", function(d){return `translate(${x_scale(d.x)}, ${y_scale(d.y)})`})
                .attr("data-entry-index", function(d, i){return i})



            circle_containers.append("circle").attr(circle_attrs);
            circle_containers.append("text").text(function(d){return d.token_text;})
                .attr('dy', -16).style("text-anchor", "middle").style("font-size", "16px")
            circle_containers.append("text").text(function(d){return d.circle_text;})
                .attr('dy', "0.3em").style("text-anchor", "middle")
                .style("font-size", "14px").style("font-weight", "bold")

            circle_containers
                .on("mouseover", function(d, i) {d3.select(this).style("font-weight", "bold");})
                .on("mouseout", function(d, i) {d3.select(this).style("font-weight", "normal");})
                .on("click", function(d, i) {callback_on_click(parseInt(this.dataset.entryIndex))});
            // note: this.dataset.elemIndex will point to element's "data-entry-index" property that we set above
        }

    </script>

    <script> // this script defines the visual interface components

        var prompt_screen = document.getElementById('lm_prompt_screen');
        var prompt_input = prompt_screen.getElementsByClassName('input_prompt')[0];
        var prompt_next_button = prompt_screen.getElementsByClassName('next')[0];
        var prompt_status = prompt_screen.getElementsByClassName('status_comment')[0];
        var generate_screen = document.getElementById('lm_generate_screen');
        var generated_text = generate_screen.getElementsByClassName("input_preprocessed")[0];

        // generator state: tokens and RNN states for all tokens that are in the textarea
        var current_tokens = [], current_lstm_states = []; // should be of same length
        var beam_search_vertices;  // current beam search tree from which user can choose


        // load model, then enable the "next" button
        document.addEventListener('DOMContentLoaded', async function() {
            await async_initialize_model();
            prompt_next_button.style.opacity = 1.0;
            prompt_next_button.onclick = on_prompt_next
            prompt_status.innerHTML = `Just kidding, you can leave it blank. The machine doesn't need you :)`
        });

        async function on_prompt_next() {
            prompt_status.innerHTML = "Processing...";
            bootstrap_from_prefix(prompt_input.value);
            generate_screen.getElementsByClassName("button_add_greedy")[0].onclick = add_token_greedy;
            generate_screen.getElementsByClassName("button_backspace")[0].onclick = remove_last_token;
            generate_screen.getElementsByClassName("button_restart")[0].onclick = reset_to_prompt_screen;
            prompt_screen.style.display = 'none';
            generate_screen.style.display = 'block';
        }

        async function reset_to_prompt_screen() {
            prompt_status.innerHTML = "Another prompt, perhaps?";
            current_tokens = current_lstm_states = [];
            beam_search_vertices = undefined;
            prompt_screen.style.display = 'block';
            generate_screen.style.display = 'none';
        }

        async function bootstrap_from_prefix(prefix) {
            // tokenize, bpeize and lstm-ize prefix string,
            // populate current_tokens, token_indices and current_lstm_states
            current_tokens = Array.prototype.concat([bos], preprocess(prefix));
            generated_text.value = current_tokens.slice(1, current_tokens.length).join(" ")
            await sleep(50);
            generated_text.style.height = Math.max(Math.round(generated_text.scrollHeight), 64) + 'px';


            var token_indices = current_tokens.map(tok => (tok in token_to_ix ? token_to_ix[tok] : token_to_ix[unk]));
            var [prev_logits, prev_hid, prev_cell] = get_initial_state();

            for (let t = 0; t < token_indices.length; t++) {
                token_ix = tf.tensor([token_indices[t]], null, "int32").reshape([1, -1]);
                [prev_logits, prev_hid, prev_cell] = model.predict([token_ix, prev_hid, prev_cell]);
                current_lstm_states.push([prev_logits, prev_hid, prev_cell]);
            }
            await redraw_user_interface();
        }

        async function redraw_user_interface() {
            generated_text.value = current_tokens.slice(1, current_tokens.length).join(" ")
            generated_text.scrollTop = generated_text.scrollHeight;
            var [prev_logits, prev_hid, prev_cell] = current_lstm_states[current_lstm_states.length - 1];
            beam_search_vertices = await generate_beam_search_vertices([prev_logits, prev_hid, prev_cell]);
            draw_beam_search_vertices(beam_search_vertices, callback_on_click=add_tokens_from_chosen_vertex);
        }

        async function add_token_greedy() {
            var [prev_logits, prev_hid, prev_cell] = current_lstm_states[current_lstm_states.length - 1];
            var token_ix = prev_logits.argMax(-1);
            current_lstm_states.push(model.predict([token_ix.reshape([1, -1]), prev_hid, prev_cell]));
            current_tokens.push(vocab[(await token_ix.array())[0]]);
            await redraw_user_interface();
        }

        async function remove_last_token() {
            if (current_tokens.length <= 1) return;
            current_tokens.pop();
            current_lstm_states.pop();
            await redraw_user_interface();
        }

        async function add_tokens_from_chosen_vertex(chosen_index) {
            var current_vertex = beam_search_vertices[chosen_index];
            var additional_tokens = [];
            while (current_vertex.parent_index != -1) {
                additional_tokens.push(current_vertex.token_text);
                current_vertex = beam_search_vertices[current_vertex.parent_index];
            }

            additional_tokens = additional_tokens.reverse();
            var token_indices = additional_tokens.map(tok => (tok in token_to_ix ? token_to_ix[tok] : token_to_ix[unk]));
            var [prev_logits, prev_hid, prev_cell] = current_lstm_states[current_lstm_states.length - 1];

            for (let t = 0; t < token_indices.length; t++) {
                current_tokens.push(additional_tokens[t]);
                token_ix = tf.tensor([token_indices[t]], null, "int32").reshape([1, -1]);
                [prev_logits, prev_hid, prev_cell] = model.predict([token_ix, prev_hid, prev_cell]);
                current_lstm_states.push([prev_logits, prev_hid, prev_cell]);
            }
            await redraw_user_interface();
        }

    </script>




</div>



</div>

</div>